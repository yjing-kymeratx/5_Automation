{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Suppress RDKit warnings\n",
    "def mute_rdkit():\n",
    "    from rdkit import RDLogger\n",
    "    lg = RDLogger.logger()\n",
    "    lg.setLevel(RDLogger.CRITICAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_value(idx, list_train, list_val, list_test):\n",
    "    if idx in list_train:\n",
    "        return 'Training'\n",
    "    elif idx in list_val:\n",
    "        return 'Validation'\n",
    "    elif idx in list_test:\n",
    "        return 'Test' \n",
    "    else:\n",
    "        return 'Training'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ================================================================================================\n",
    "## ==================================== random split ==============================================\n",
    "## ================================================================================================\n",
    "def nFoldSplit_random(dataTable, colName_mid='Compound Name', CV=10, rng=666666, hasVal=True):\n",
    "    ds_size = dataTable.shape[0]\n",
    "    assert CV*2 < ds_size, f\"\\tError, the dataset (N={ds_size}) is too small to do a {CV}_fold split! Please decrease the CV value ({CV})\"\n",
    "\n",
    "    dataTable_split = dataTable[[colName_mid]].reset_index(drop=True)\n",
    "    list_mol_idx = dataTable_split.index.to_numpy()\n",
    "\n",
    "    # Shuffle the list using random seed\n",
    "    import numpy as np\n",
    "    np.random.seed(rng)\n",
    "    np.random.shuffle(list_mol_idx)\n",
    "\n",
    "    # Split the list into N sublists\n",
    "    sublists = np.array_split(list_mol_idx, CV)\n",
    "    idx_test = sublists[CV-1]\n",
    "    idx_val = sublists[CV-2] if hasVal else []\n",
    "    idx_train = [i for i in list_mol_idx if i not in idx_test and i not in idx_val]\n",
    "    print(f\"\\tSplit the data (n={len(list_mol_idx)}) into Train({len(idx_train)}), Val({len(idx_val)}), and Test({len(idx_test)})\")\n",
    "\n",
    "    # Apply the function to assign values to the new column 'A'\n",
    "    dataTable_split[f'Split'] = dataTable_split.index.to_series().apply(lambda x: assign_value(x, idx_train, idx_val, idx_test))\n",
    "    return dataTable_split\n",
    "\n",
    "\n",
    "## ================================================================================================\n",
    "## ==================================== temporal split ============================================\n",
    "## ================================================================================================\n",
    "def nFoldSplit_temporal(dataTable, colName_mid='Compound Name', colName_date=\"Created On\", CV=10, hasVal=True):\n",
    "    ds_size = dataTable.shape[0]\n",
    "    assert CV*2 < ds_size, f\"\\tError, the dataset (N={ds_size}) is too small to do a {CV}_fold split! Please decrease the CV value ({CV})\"\n",
    "\n",
    "    dataTable_split = dataTable[[colName_mid, colName_date]].reset_index(drop=True)\n",
    "    try:\n",
    "        import pandas as pd\n",
    "        dataTable_split[colName_date] = dataTable_split[colName_date].str.split(';').str[0]\n",
    "        dataTable_split[\"date_formatted\"] = pd.to_datetime(dataTable_split[colName_date])\n",
    "        dataTable_split = dataTable_split.sort_values(by=[\"date_formatted\"], ascending=[True])\n",
    "    except Exception as e:\n",
    "        print(f\"\\tWarning! The mol date column <{colName_date}> cannot be formatted. Error mgs: {e}\")\n",
    "    else:\n",
    "        # Split the list into N sublists\n",
    "        import numpy as np\n",
    "        list_mol_idx = dataTable_split.index.to_numpy()\n",
    "        try:\n",
    "            sublists = np.array_split(list_mol_idx, CV)\n",
    "        except Exception as e:\n",
    "            print(f\"\\tWarning! Cannot split data based on date. Error mgs: {e}\")\n",
    "        else:\n",
    "            idx_test = sublists[CV-1]\n",
    "            idx_val = sublists[CV-2] if hasVal else []\n",
    "            idx_train = [i for i in list_mol_idx if i not in idx_test and i not in idx_val]\n",
    "            print(f\"\\tSplit the data (n={len(list_mol_idx)}) into Train({len(idx_train)}), Val({len(idx_val)}), and Test({len(idx_test)})\")\n",
    "            \n",
    "            # Apply the function to assign values to the new column 'A'\n",
    "            dataTable_split[f'Split'] = dataTable_split.index.to_series().apply(lambda x: assign_value(x, idx_train, idx_val, idx_test))\n",
    "    return dataTable_split \n",
    "\n",
    "\n",
    "## ================================================================================================\n",
    "## ==================================== diverse split ============================================\n",
    "## ================================================================================================\n",
    "def nFoldSplit_diverse(dataTable, colName_mid='Compound Name', colName_smi=\"Structure\", CV=10, hasVal=True):\n",
    "    ds_size = dataTable.shape[0]\n",
    "    assert CV*2 < ds_size, f\"\\tError, the dataset (N={ds_size}) is too small to do a {CV}_fold split! Please decrease the CV value ({CV})\"\n",
    "\n",
    "    dataTable_split = dataTable[[colName_mid, colName_smi]].sample(frac=1).reset_index(drop=True)\n",
    "    smiles_list = dataTable_split[colName_smi].to_list()\n",
    "\n",
    "    ## calc the fps\n",
    "    mute_rdkit()\n",
    "    import numpy as np\n",
    "    from rdkit import Chem, DataStructs, SimDivFilters\n",
    "    from rdkit.Chem import AllChem\n",
    "    fps = [AllChem.GetMorganFingerprintAsBitVect(Chem.MolFromSmiles(smi), 3, nBits=2048) for smi in smiles_list]\n",
    "\n",
    "    ## Generate the distance matrix in advance\n",
    "    ds=[]\n",
    "    for i in range(1,len(fps)):\n",
    "        ds.extend(DataStructs.BulkTanimotoSimilarity(fps[i], fps[:i], returnDistance=True))\n",
    "\n",
    "    ## Initialize the MaxMinPicker\n",
    "    picker = SimDivFilters.MaxMinPicker()\n",
    "\n",
    "    ## define the number of mols to pick for test/validation\n",
    "    num_picks = int(ds_size/CV)\n",
    "    num_picks_real = 2*num_picks if hasVal else num_picks\n",
    "    print(num_picks_real, num_picks)\n",
    "\n",
    "    ## Select N diverse molecules from the set\n",
    "    pick_idx = picker.Pick(np.array(ds), len(fps), num_picks_real)\n",
    "    idx_test = pick_idx[:num_picks] if hasVal else pick_idx\n",
    "    idx_val = pick_idx[num_picks:] if hasVal else []\n",
    "    idx_train = [i for i in dataTable_split.index if i not in pick_idx]\n",
    "\n",
    "    # Apply the function to assign values to the new column 'A'\n",
    "    dataTable_split[f'Split'] = dataTable_split.index.to_series().apply(lambda x: assign_value(x, idx_train, idx_val, idx_test))\n",
    "\n",
    "    return dataTable_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(split_method):\n",
    "    '''\n",
    "    args = Args_Prepation(parser_desc='Preparing the input files and the descriptors')\n",
    "    fileNameIn = args.input    # '../../1_DataPrep/results/data_input_clean.csv'\n",
    "    sep = args.delimiter \n",
    "    colName_mid = args.colId    # 'Compound Name'\n",
    "    colName_smi = args.colSmi    # 'Structure'\n",
    "\n",
    "    '''\n",
    "    fileNameIn = './results/data_input_clean.csv'\n",
    "    sep =  ','\n",
    "    colName_mid = 'Compound Name'\n",
    "    colName_date = \"ADME MDCK(WT) Permeability;Concat;Run Date\"  #'Created On'    #\n",
    "    colName_smi = 'Structure'\n",
    "    # split_method = 'random'\n",
    "    CV = 10\n",
    "    rng = 666666\n",
    "    hasVal =True  \n",
    "    \n",
    "    ## ------------ load data ------------\n",
    "    import pandas as pd\n",
    "    dataTable_raw = pd.read_csv(fileNameIn, sep=sep).head(100)\n",
    "    print(f\"\\t{dataTable_raw.shape}\")\n",
    "    assert colName_mid in dataTable_raw.columns, f\"\\tColumn name for mol ID <{colName_mid}> is not in the table.\"\n",
    "        \n",
    "\n",
    "    print(f\"\\tData split method: {split_method}\")\n",
    "    ## ------------ calculate rdkit properties ------------\n",
    "    if split_method == 'random':\n",
    "        dataTable_split = nFoldSplit_random(dataTable_raw, colName_mid, CV=CV, rng=rng, hasVal=hasVal)\n",
    "\n",
    "    ## ------------ calculate mol fingerprints ------------\n",
    "    if split_method == 'temporal':\n",
    "        assert colName_date in dataTable_raw.columns, f\"\\tColumn name for date <{colName_date}> is not in the table.\"\n",
    "        dataTable_split = nFoldSplit_temporal(dataTable_raw, colName_mid, colName_date, CV=CV, hasVal=hasVal)\n",
    "\n",
    "    ## ------------ calculate chemAxon properties ------------\n",
    "    if split_method == 'diverse':\n",
    "        assert colName_smi in dataTable_raw.columns, f\"\\tColumn name for mol smiles <{colName_smi}> is not in the table.\"\n",
    "        dataTable_split = nFoldSplit_diverse(dataTable_raw, colName_mid, colName_smi, CV=10, hasVal=hasVal)\n",
    "\n",
    "\n",
    "    ## ------------ save the split ------------\n",
    "    import os\n",
    "    output_folder = './results'\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    dataTable_split.to_csv(f\"{output_folder}/data_split_{split_method}.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t(100, 12)\n",
      "\tData split method: random\n",
      "\tSplit the data (n=100) into Train(80), Val(10), and Test(10)\n",
      "\t(100, 12)\n",
      "\tData split method: temporal\n",
      "\tSplit the data (n=100) into Train(80), Val(10), and Test(10)\n",
      "\t(100, 12)\n",
      "\tData split method: diverse\n",
      "20 10\n"
     ]
    }
   ],
   "source": [
    "for split_method in ['random', 'temporal', 'diverse']:\n",
    "    main(split_method=split_method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# dataTable = pd.read_csv('./results/data_input_clean.csv')\n",
    "# dataTable_split = nFoldSplit_diverse(dataTable, colName_mid='Compound Name', colName_smi=\"Structure\", CV=10, hasVal=False)\n",
    "# dataTable_split['Split'].value_counts()\n",
    "\n",
    "# import pandas as pd\n",
    "# dataTable = pd.read_csv('./results/data_input_clean.csv')\n",
    "# dataTable_split = nFoldSplit_random(dataTable, colName_mid='Compound Name', CV=10, rng=666666, hasVal=False)\n",
    "# dataTable_split['Split'].value_counts()\n",
    "\n",
    "# import pandas as pd\n",
    "# dataTable = pd.read_csv('./results/data_input_clean.csv')\n",
    "# dataTable_split = nFoldSplit_temporal(dataTable, colName_mid='Compound Name', colName_date='ADME MDCK(WT) Permeability;Concat;Run Date', CV=10, hasVal=False)\n",
    "# dataTable_split['Split'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t(3830, 12)\n",
      "\tData split method: diverse\n",
      "\tSplit the data (n=3830) into Train(3064), Val(383), and Test(383)\n"
     ]
    }
   ],
   "source": [
    "!/mnt/data0/Research/0_Test/cx_pKa/bash2py_yjing_local.bash python ./Data_Split.py -i \"./results/data_input_clean.csv\" -d \",\" --colId 'Compound Name' --colSmi 'Structure' --colDate \"ADME MDCK(WT) Permeability;Concat;Run Date\" --split 'diverse' --CV 10 --rng 666666 --hasVal True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if __name__ == '__main__':\n",
    "#     main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
