{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step_3_Model_building(dataDict_ds, args, n_jobs=-1, saveModel=True, tmpFolder='./tmp'):\n",
    "    if True:\n",
    "        ## get parameters from args\n",
    "        rng = int(args.randomSeed)\n",
    "        mType = args.modelType\n",
    "        m_rf = _str_2_bool(args.model_rf)\n",
    "        m_li = _str_2_bool(args.model_linear)\n",
    "        m_svm = _str_2_bool(args.model_svm)\n",
    "        m_mlp = _str_2_bool(args.model_mlp)\n",
    "        m_knn = _str_2_bool(args.model_knn)\n",
    "        m_knnk = int(args.model_knnk)\n",
    "        m_xgb = _str_2_bool(args.model_xgb)\n",
    "        HPT = _str_2_bool(args.HPT)\n",
    "\n",
    "        tba = True    # retrain_by_all\n",
    "\n",
    "        ## get model\n",
    "        dict_models = {}\n",
    "\n",
    "    if mType == 'regression':\n",
    "        ## Random Forests models\n",
    "        if m_rf:\n",
    "            sk_model, s_space = ML_Models.select_ML_methods(mType, 'RF', rng=rng, n_jobs=n_jobs)\n",
    "            dict_models['RF'] = _R_Model(dataDict_ds, sk_model, modelName=f\"{mType}_RF\", rng=rng, n_jobs=n_jobs, HPT=HPT, search_space=s_space, retrain_by_all=tba, tmpFolder=tmpFolder)\n",
    "            \n",
    "            ## Feature Importance\n",
    "            RF_model_feature_importance = dict_models['RF'].model.feature_importances_\n",
    "            Dict_RF_FI = {}\n",
    "            for feature, importance in zip(dataDict_ds['Training_X'].columns, RF_model_feature_importance): \n",
    "                print(f\"{feature}: {importance:.4f}\")\n",
    "                Dict_RF_FI[feature] = {}\n",
    "                Dict_RF_FI[feature]['Feature'] = feature\n",
    "                Dict_RF_FI[feature]['FeatureImportance'] = importance\n",
    "\n",
    "            Table_RF_FI = pd.DataFrame.from_dict(Dict_RF_FI).T\n",
    "            Table_RF_FI = Table_RF_FI.sort_values(by='FeatureImportance', ascending=False).reset_index(drop=True)\n",
    "            Table_RF_FI.to_csv(f'{tmpFolder}/{mType}_RF_featureImportance.csv', index=False)\n",
    "\n",
    "            ##\n",
    "            fig, ax = plt.subplots()\n",
    "            Table_RF_FI.head(20).plot.barh(x='Feature', y='FeatureImportance', ax=ax)\n",
    "            ax.set_title(\"Random Forest Feature Importances (MDI)\")\n",
    "            # ax.figure.tight_layout()\n",
    "            ax.figure.savefig(f'{tmpFolder}/{mType}_RF_featureImportance.png')\n",
    "\n",
    "        ## linear models\n",
    "        if m_li:\n",
    "            sk_model, s_space = ML_Models.select_ML_methods(mType, 'linear', rng=rng, n_jobs=n_jobs)            \n",
    "            dict_models['linear'] = _R_Model(dataDict_ds, sk_model, modelName=f\"{mType}_linear\", rng=rng, n_jobs=n_jobs, HPT=False, search_space=s_space, retrain_by_all=tba, tmpFolder=tmpFolder)\n",
    "\n",
    "        ## SVM models\n",
    "        if m_svm:\n",
    "            sk_model, s_space = ML_Models.select_ML_methods(mType, 'SVM', rng=rng, n_jobs=n_jobs)            \n",
    "            dict_models['SVM'] = _R_Model(dataDict_ds, sk_model, modelName=f\"{mType}_SVM\", rng=rng, n_jobs=n_jobs, HPT=HPT, search_space=s_space, retrain_by_all=tba, tmpFolder=tmpFolder)\n",
    "\n",
    "        ## Multi-layer perceptron models\n",
    "        if m_mlp:\n",
    "            sk_model, s_space = ML_Models.select_ML_methods(mType, 'MLP', rng=rng, n_jobs=n_jobs)            \n",
    "            dict_models['MLP'] = _R_Model(dataDict_ds, sk_model, modelName=f\"{mType}_MLP\", rng=rng, n_jobs=n_jobs, HPT=HPT, search_space=s_space, retrain_by_all=tba, tmpFolder=tmpFolder)\n",
    "\n",
    "        ## K-nearest neighbor models\n",
    "        if m_knn:\n",
    "            sk_model, s_space = ML_Models.select_ML_methods(mType, 'KNN', rng=rng, n_jobs=n_jobs, knnk=m_knnk)            \n",
    "            dict_models['KNN'] = _R_Model(dataDict_ds, sk_model, modelName=f\"{mType}_KNN\", rng=rng, n_jobs=n_jobs, HPT=HPT, search_space=s_space, retrain_by_all=tba, tmpFolder=tmpFolder)\n",
    "\n",
    "    elif mType == 'classification': \n",
    "        ## Random Forests models\n",
    "        if m_rf:\n",
    "            sk_model, s_space = ML_Models.select_ML_methods(mType, 'RF', rng=rng, n_jobs=n_jobs)\n",
    "            dict_models['RF'] = _C_Model(dataDict_ds, sk_model, modelName=f\"{mType}_RF\", rng=rng, n_jobs=n_jobs, HPT=HPT, search_space=s_space, retrain_by_all=tba, tmpFolder=tmpFolder)\n",
    "            \n",
    "            ## Feature Importance\n",
    "            RF_model_feature_importance = dict_models['RF'].model.feature_importances_\n",
    "            Dict_RF_FI = {}\n",
    "            for feature, importance in zip(dataDict_ds['Training_X'].columns, RF_model_feature_importance): \n",
    "                print(f\"{feature}: {importance:.4f}\")\n",
    "                Dict_RF_FI[feature] = {}\n",
    "                Dict_RF_FI[feature]['Feature'] = feature\n",
    "                Dict_RF_FI[feature]['FeatureImportance'] = importance\n",
    "\n",
    "            Table_RF_FI = pd.DataFrame.from_dict(Dict_RF_FI).T\n",
    "            Table_RF_FI.to_csv(f'{tmpFolder}/{mType}_RF_featureImportance.csv', index=False)             \n",
    "            ##\n",
    "            fig, ax = plt.subplots()\n",
    "            Table_RF_FI.plot.barh(ax=ax)\n",
    "            ax.set_title(\"Random Forest Feature Importances (MDI)\")\n",
    "            ax.figure.tight_layout()\n",
    "            ax.savefig(f'{tmpFolder}/{mType}_RF_featureImportance.png')\n",
    "\n",
    "        ## linear models\n",
    "        if m_li:\n",
    "            sk_model, s_space = ML_Models.select_ML_methods(mType, 'linear', rng=rng, n_jobs=n_jobs)            \n",
    "            dict_models['linear'] = _C_Model(dataDict_ds, sk_model, modelName=f\"{mType}_linear\", rng=rng, n_jobs=n_jobs, HPT=False, search_space=s_space, retrain_by_all=tba, tmpFolder=tmpFolder)\n",
    "\n",
    "        ## SVM models\n",
    "        if m_svm:\n",
    "            sk_model, s_space = ML_Models.select_ML_methods(mType, 'SVM', rng=rng, n_jobs=n_jobs)            \n",
    "            dict_models['SVM'] = _C_Model(dataDict_ds, sk_model, modelName=f\"{mType}_SVM\", rng=rng, n_jobs=n_jobs, HPT=HPT, search_space=s_space, retrain_by_all=tba, tmpFolder=tmpFolder)\n",
    "\n",
    "        ## Multi-layer perceptron models\n",
    "        if m_mlp:\n",
    "            sk_model, s_space = ML_Models.select_ML_methods(mType, 'MLP', rng=rng, n_jobs=n_jobs)            \n",
    "            dict_models['MLP'] = _C_Model(dataDict_ds, sk_model, modelName=f\"{mType}_MLP\", rng=rng, n_jobs=n_jobs, HPT=HPT, search_space=s_space, retrain_by_all=tba, tmpFolder=tmpFolder)\n",
    "\n",
    "        ## K-nearest neighbor models\n",
    "        if m_knn:\n",
    "            sk_model, s_space = ML_Models.select_ML_methods(mType, 'KNN', rng=rng, n_jobs=n_jobs, knnk=m_knnk)            \n",
    "            dict_models['KNN'] = _C_Model(dataDict_ds, sk_model, modelName=f\"{mType}_KNN\", rng=rng, n_jobs=n_jobs, HPT=HPT, search_space=s_space, retrain_by_all=tba, tmpFolder=tmpFolder)\n",
    "        \n",
    "        ## XG-Boosting models\n",
    "        if m_xgb:\n",
    "            sk_model, s_space = ML_Models.select_ML_methods(mType, 'XGBoost', rng=rng, n_jobs=n_jobs)            \n",
    "            dict_models['XGBoost'] = _C_Model(dataDict_ds, sk_model, modelName=f\"{mType}_XGBoost\", rng=rng, n_jobs=n_jobs, HPT=HPT, search_space=s_space, retrain_by_all=tba, tmpFolder=tmpFolder)\n",
    "\n",
    "    else:\n",
    "        print(f\"\\tError! No selected ML methods for modeling. Either <regression> or <classification>\")\n",
    "\n",
    "    if saveModel:\n",
    "        os.makedirs(f'{tmpFolder}/models') if not os.path.exists(f'{tmpFolder}/models') else print(f'\\t---->{tmpFolder}/models/ is existing\\n')\n",
    "        fileName_modelDict = f'{tmpFolder}/models/All_models.dict'\n",
    "        with open(fileName_modelDict, 'wb') as mofh:\n",
    "            pickle.dump(dict_models, mofh)\n",
    "            print(f'\\tThe Dict contains all models has been saved to {fileName_modelDict}\\n')\n",
    "    return dict_models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ----------- regression model -----------\n",
    "def _R_Model(dataDict_ds, sk_model, modelName=\"ML_model\", rng=666666, n_jobs=-1, HPT=True, search_space=None, retrain_by_all=False, saveModel=True, saveFig=True, tmpFolder='./tmp'):\n",
    "    print(f\"\\n\\t-------------------- Now building the model <{modelName}> --------------------\")\n",
    "    myModel = ML_Models.Regression_Model(myScikitModel=sk_model, modelName=modelName, rng=rng, n_jobs=n_jobs)\n",
    "    \n",
    "    ## train the model\n",
    "    print(f\"\\t ----- Now start training the model -----\")\n",
    "    myModel.Train(dataDict_ds['Training_X'], dataDict_ds['Training_y'], printLog=True, HPT=HPT, search_space=search_space)\n",
    "    myModel.Evaluate(dataDict_ds['Training_X'], dataDict_ds['Training_y'], ds_label='Training', printLog=True, plotResult=True)\n",
    "    \n",
    "    ## validate the model\n",
    "    print(f\"\\t ----- Now start evaluating the model using validation set -----\")\n",
    "    myModel.Evaluate(dataDict_ds['Validation_X'], dataDict_ds['Validation_y'], ds_label='Validation', printLog=True, plotResult=True)    \n",
    "    \n",
    "    ## test the model\n",
    "    print(f\"\\t ----- Now start evaluating the model using test set -----\")\n",
    "    myModel.Evaluate(dataDict_ds['Test_X'], dataDict_ds['Test_y'], ds_label='Test', printLog=True, plotResult=True)\n",
    "\n",
    "\n",
    "    ## plot all\n",
    "    myModel.plots['All'] = myModel._Plot_Pred_VS_Expt(dataTable=myModel.predictions, \n",
    "                                                      label_x='Prediction', label_y='Experiment', color_by='DataSet', \n",
    "                                                      diagonal=True, sideHist=False, figTitle=None) \n",
    "    ## retrain the model using all\n",
    "    if retrain_by_all:\n",
    "        dataDict_ds_all_X = pd.concat([dataDict_ds[f\"{dl}_X\"] for dl in [\"Training\", \"Validation\", \"Test\"]])\n",
    "        dataDict_ds_all_y = pd.concat([dataDict_ds[f\"{dl}_y\"] for dl in [\"Training\", \"Validation\", \"Test\"]])\n",
    "        myModel.Train(dataDict_ds_all_X, dataDict_ds_all_y, HPT=False, printLog=True)\n",
    "\n",
    "    ## save model and figs\n",
    "    saveModel = True   \n",
    "    if saveModel:\n",
    "        ## save DIY model files\n",
    "        os.makedirs(f'{tmpFolder}/models') if not os.path.exists(f'{tmpFolder}/models') else print(f'\\t---->{tmpFolder}/models/ is existing\\n')\n",
    "        fileName_modelObj = f'{tmpFolder}/models/{modelName}.DIYmodel'\n",
    "        with open(fileName_modelObj, 'wb') as mofh:\n",
    "            pickle.dump(myModel, mofh)\n",
    "            print(f'\\tThe DIYML model <{modelName}> has been saved to {fileName_modelObj}\\n')   \n",
    "\n",
    "        ## save Scikit Learn model files\n",
    "        # curFolder = '.'\n",
    "        # os.makedirs(f'{curFolder}/models') if not os.path.exists(f'{curFolder}/models') else print(f'\\t---->{curFolder}/models/ is existing\\n')\n",
    "        fileName_SKmodel = f'{tmpFolder}/models/{modelName}.SKmodel'\n",
    "        with open(fileName_SKmodel, 'wb') as mofh:\n",
    "            pickle.dump(myModel, mofh)\n",
    "            print(f'\\tThe SK-learn model <{modelName}> has been saved to {fileName_SKmodel}\\n') \n",
    "\n",
    "    if saveFig:\n",
    "        ## save to tmp folder\n",
    "        os.makedirs(f'{tmpFolder}/figures') if not os.path.exists(f'{tmpFolder}/figures') else print(f'\\t---->{tmpFolder}/figures/ is existing\\n') \n",
    "        for fig_label in myModel.plots:\n",
    "            fileName_fig = f'{tmpFolder}/figures/{modelName}_{fig_label}.png'\n",
    "            myModel.plots[fig_label].savefig(fileName_fig)\n",
    "\n",
    "        ## save to model folder\n",
    "        curFolder = os.getcwd()  \n",
    "        os.makedirs(f'{curFolder}/models') if not os.path.exists(f'{curFolder}/models') else print(f'\\t---->{curFolder}/models/ is existing\\n')\n",
    "        ml_method = modelName.split('_')[1]\n",
    "        os.makedirs(f'{curFolder}/models/{ml_method}') if not os.path.exists(f'{curFolder}/models/{ml_method}') else print(f'\\t---->{curFolder}/models/{ml_method} is existing\\n')\n",
    "        os.makedirs(f'{curFolder}/models/{ml_method}/figures') if not os.path.exists(f'{curFolder}/models/{ml_method}/figures') else print(f'\\t---->{curFolder}/models/{ml_method}/figures is existing\\n')\n",
    "        for fig_label in myModel.plots:\n",
    "        \n",
    "            figName_model = f'{curFolder}/models/{ml_method}/figures/{modelName}_{fig_label}.png'\n",
    "            myModel.plots[fig_label].savefig(figName_model)    \n",
    "    return myModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ----------- classification model -----------\n",
    "def _C_Model(dataDict_ds, sk_model, modelName=\"ML_model\", rng=666666, n_jobs=-1, HPT=True, search_space=None, retrain_by_all=False, saveModel=True, saveFig=True, tmpFolder='./tmp'):\n",
    "    print(f\"\\n\\t-------------------- Now building the model <{modelName}> --------------------\")\n",
    "    myModel = ML_Models.Classification_Model(myScikitModel=sk_model, modelName=modelName, rng=rng, n_jobs=n_jobs)\n",
    "    \n",
    "    ## train the model\n",
    "    print(f\"\\t ----- Now start training the model -----\")\n",
    "    myModel.Train(dataDict_ds['Training_X'], dataDict_ds['Training_y'], printLog=True, HPT=HPT, search_space=search_space)\n",
    "    \n",
    "    ## validate the model\n",
    "    print(f\"\\t ----- Now start evaluating the model using validation set -----\")\n",
    "    myModel.Evaluate(dataDict_ds['Validation_X'], dataDict_ds['Validation_y'], ds_label='Validation', estCutoff=True, printLog=True, plotResult=True)\n",
    "    myModel.Evaluate(dataDict_ds['Training_X'], dataDict_ds['Training_y'], ds_label='Training', estCutoff=False, printLog=True, plotResult=True)\n",
    "\n",
    "    ## test the model\n",
    "    print(f\"\\t ----- Now start evaluating the model using test set -----\")\n",
    "    myModel.Evaluate(dataDict_ds['Test_X'], dataDict_ds['Test_y'], ds_label='Test', estCutoff=False, printLog=True, plotResult=False)\n",
    "    \n",
    "    ## plot all\n",
    "    # myModel.plots['All'] = None \n",
    "\n",
    "    ## retrain the model using all\n",
    "    if retrain_by_all:\n",
    "        dataDict_ds_all_X = pd.concat([dataDict_ds[f\"{dl}_X\"] for dl in [\"Training\", \"Validation\", \"Test\"]])\n",
    "        dataDict_ds_all_y = pd.concat([dataDict_ds[f\"{dl}_y\"] for dl in [\"Training\", \"Validation\", \"Test\"]])\n",
    "        myModel.Train(dataDict_ds_all_X, dataDict_ds_all_y, HPT=False, printLog=True)\n",
    "\n",
    "    ## save model and figs    \n",
    "    if saveModel:\n",
    "        ## save DIY model files\n",
    "        os.makedirs(f'{tmpFolder}/models') if not os.path.exists(f'{tmpFolder}/models') else print(f'\\t---->{tmpFolder}/models/ is existing\\n')\n",
    "        fileName_modelObj = f'{tmpFolder}/models/{modelName}.DIYmodel'\n",
    "        with open(fileName_modelObj, 'wb') as mofh:\n",
    "            pickle.dump(myModel, mofh)\n",
    "            print(f'\\tThe DIYML model <{modelName}> has been saved to {fileName_modelObj}\\n')        \n",
    "        \n",
    "        ## save Scikit Learn model files\n",
    "        curFolder = '.'\n",
    "        os.makedirs(f'{curFolder}/models') if not os.path.exists(f'{curFolder}/models') else print(f'\\t---->{curFolder}/models/ is existing\\n')\n",
    "        fileName_SKmodel = f'{curFolder}/models/{modelName}.model'\n",
    "        with open(fileName_SKmodel, 'wb') as mofh:\n",
    "            pickle.dump(myModel, mofh)\n",
    "            print(f'\\tThe DIYML model <{modelName}> has been saved to {fileName_SKmodel}\\n') \n",
    "\n",
    "    if saveFig:\n",
    "        os.makedirs(f'{tmpFolder}/figures') if not os.path.exists(f'{tmpFolder}/figures') else print(f'\\t---->{tmpFolder}/figures/ is existing\\n') \n",
    "        for fig_label in myModel.plots:\n",
    "            fileName_fig = f'{tmpFolder}/figures/{modelName}_{fig_label}.png'\n",
    "            myModel.plots[fig_label].savefig(fileName_fig)\n",
    "    return myModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "modelType=\"regression\"\n",
    "\n",
    "\n",
    "m_rf = _str_2_bool(args.model_rf)\n",
    "m_li = _str_2_bool(args.model_linear)\n",
    "m_svm = _str_2_bool(args.model_svm)\n",
    "m_mlp = _str_2_bool(args.model_mlp)\n",
    "m_knn = _str_2_bool(args.model_knn)\n",
    "m_knnk = int(args.model_knnk)\n",
    "m_xgb = _str_2_bool(args.model_xgb)\n",
    "HPT = _str_2_bool(args.HPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "ADME MDCK(WT) Permeability;Mean;A to B Papp (10^-6 cm/s);(Num)",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "4d4726bd-7b73-47c8-aa70-da70511f11ba",
       "rows": [
        [
         "0",
         "0.298012837"
        ],
        [
         "1",
         "0.767547486"
        ],
        [
         "2",
         "0.186650854"
        ],
        [
         "3",
         "0.482283502"
        ],
        [
         "4",
         "0.642137936"
        ],
        [
         "5",
         "15.40730786"
        ],
        [
         "6",
         "0.4263793"
        ],
        [
         "7",
         "0.328749535"
        ],
        [
         "8",
         "0.301588601"
        ],
        [
         "9",
         "2.207218336"
        ],
        [
         "10",
         "0.40597628"
        ],
        [
         "11",
         "1.695580789333333"
        ],
        [
         "12",
         "4.072580829"
        ],
        [
         "13",
         "2.915035749"
        ],
        [
         "14",
         "6.68827979"
        ],
        [
         "15",
         "3.178919928"
        ],
        [
         "16",
         "1.678909414"
        ],
        [
         "17",
         "1.15311139"
        ],
        [
         "18",
         "1.987887107"
        ],
        [
         "19",
         "2.407377305"
        ],
        [
         "20",
         "30.6350563"
        ],
        [
         "21",
         "32.95390136"
        ],
        [
         "22",
         "12.01708991"
        ],
        [
         "23",
         "0.721505228"
        ],
        [
         "24",
         "1.241552623"
        ],
        [
         "25",
         "1.029547212"
        ],
        [
         "26",
         "0.901678682"
        ],
        [
         "27",
         "1.276835703"
        ],
        [
         "28",
         "0.960066134"
        ],
        [
         "29",
         "1.32030156"
        ],
        [
         "30",
         "1.747981257"
        ],
        [
         "31",
         "1.631369078"
        ],
        [
         "32",
         "1.1"
        ],
        [
         "33",
         "0.805252003"
        ],
        [
         "34",
         "1.331586761"
        ],
        [
         "35",
         "1.555592407"
        ],
        [
         "36",
         "2.015627116"
        ],
        [
         "37",
         "2.572549174"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 38
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ADME MDCK(WT) Permeability;Mean;A to B Papp (10^-6 cm/s);(Num)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.298013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.767547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.186651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.482284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.642138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>15.407308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.426379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.328750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.301589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2.207218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.405976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.695581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4.072581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2.915036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>6.688280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3.178920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.678909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.153111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.987887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2.407377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>30.635056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>32.953901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>12.017090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.721505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1.241553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1.029547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.901679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1.276836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.960066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1.320302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1.747981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1.631369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.805252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1.331587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1.555592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2.015627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2.572549</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ADME MDCK(WT) Permeability;Mean;A to B Papp (10^-6 cm/s);(Num)\n",
       "0                                            0.298013             \n",
       "1                                            0.767547             \n",
       "2                                            0.186651             \n",
       "3                                            0.482284             \n",
       "4                                            0.642138             \n",
       "5                                           15.407308             \n",
       "6                                            0.426379             \n",
       "7                                            0.328750             \n",
       "8                                            0.301589             \n",
       "9                                            2.207218             \n",
       "10                                           0.405976             \n",
       "11                                           1.695581             \n",
       "12                                           4.072581             \n",
       "13                                           2.915036             \n",
       "14                                           6.688280             \n",
       "15                                           3.178920             \n",
       "16                                           1.678909             \n",
       "17                                           1.153111             \n",
       "18                                           1.987887             \n",
       "19                                           2.407377             \n",
       "20                                          30.635056             \n",
       "21                                          32.953901             \n",
       "22                                          12.017090             \n",
       "23                                           0.721505             \n",
       "24                                           1.241553             \n",
       "25                                           1.029547             \n",
       "26                                           0.901679             \n",
       "27                                           1.276836             \n",
       "28                                           0.960066             \n",
       "29                                           1.320302             \n",
       "30                                           1.747981             \n",
       "31                                           1.631369             \n",
       "32                                           1.100000             \n",
       "33                                           0.805252             \n",
       "34                                           1.331587             \n",
       "35                                           1.555592             \n",
       "36                                           2.015627             \n",
       "37                                           2.572549             "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pdy = pd.read_csv('./results/data_input_4_ModelBuilding.csv').iloc[:, 1:2]\n",
    "pdy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################################################\n",
    "############################# Regression model done #####################################\n",
    "#########################################################################################\n",
    "class Regression_Model(object):\n",
    "    ## <===================== model initiation =====================>\n",
    "    def __init__(self,  myScikitModel=None, modelName='Regression_Model', log_y=True, rng=666666, n_jobs=-1):\n",
    "        assert myScikitModel is not None, f\"\\tWarning! Please define an initiated RDKit ML model\"\n",
    "        self._name = modelName\n",
    "        self._rng = rng\n",
    "        self._n_jobs = n_jobs\n",
    "        self.model = myScikitModel\n",
    "        self.log_y = log_y\n",
    "        self.HPT_Results = {}\n",
    "        self.predictions = None\n",
    "        self.performance = {}\n",
    "        self.plots = {}\n",
    "            \n",
    "    ## <===================== model training =====================>\n",
    "    def Train(self, X, y, printLog=True, HPT=False, search_space=None):\n",
    "        ## count time\n",
    "        import time\n",
    "        beginTime = time.time()\n",
    "        ## ----------------------------------------------------------------\n",
    "        if self.log_y:\n",
    "            import numpy as np\n",
    "            y = np.array(y).reshape((len(y), ))\n",
    "            y = np.log10(y)\n",
    "        ## ------------ hyper parameter search ------------\n",
    "        if HPT:\n",
    "            self._HyperParamSearch(X, y, search_space=search_space, printLog=printLog)\n",
    "        \n",
    "        ## ------------ fit the model ------------\n",
    "        self.model.fit(X, y)\n",
    "       \n",
    "        ## ----------------------------------------------------------------\n",
    "        print(f\"\\tModel construction costs time = {(time.time()-beginTime):.2f} s ................\")\n",
    "        return None\n",
    "\n",
    "    ## <===================== model evaluation =====================>\n",
    "    def MakePrediction(self, X):\n",
    "        y_pred = self.model.predict(X)\n",
    "        if self.log_y:\n",
    "            y_pred = 10**(y_pred)\n",
    "        return y_pred\n",
    "\n",
    "    def Evaluate(self, X, y, ds_label='TBD', printLog=True, plotResult=False):  \n",
    "        ## make prediction\n",
    "        y_pred = self.MakePrediction(X)\n",
    "\n",
    "        ## save prediction\n",
    "        import copy\n",
    "        df_predictions = copy.deepcopy(y)\n",
    "        df_predictions['Experiment'] = df_predictions[y.columns[0]]\n",
    "        df_predictions['DataSet'] = ds_label\n",
    "        df_predictions['Prediction'] = y_pred\n",
    "        self.predictions = pd.concat([self.predictions, df_predictions]) if self.predictions is not None else df_predictions\n",
    "\n",
    "        ## calcualte statistics\n",
    "        print(f\"\\tEvaluation results of the {ds_label} dataset:\")\n",
    "        self.performance[ds_label] = self._CalcScores(y_pred=y_pred, y_true=y.to_numpy(), printLog=printLog)\n",
    "        \n",
    "        ## plotting\n",
    "        if plotResult:\n",
    "            self.plots[ds_label] = self._Plot_Pred_VS_Expt(dataTable=df_predictions,\n",
    "                                                           label_x='Prediction', \n",
    "                                                           label_y='Experiment',\n",
    "                                                           color_by='DataSet',\n",
    "                                                           figTitle=f\"Pred VS Expt ({ds_label})\")\n",
    "        return None\n",
    "\n",
    "    ## <===================== HPTunning =====================>\n",
    "    def _HyperParamSearch(self, X, y, search_space=None, search_method='grid', scoring='neg_mean_absolute_error', nFolds=5, printLog=True):\n",
    "        ## count time\n",
    "        import time\n",
    "        beginTime = time.time()\n",
    "        ## --------------------------------\n",
    "        print(f\"\\tStart Hyper-Parameter Tunning ...\")\n",
    "        SearchResults = {'best_model': None, 'best_score':None, 'best_param':None}\n",
    "        \n",
    "        ##\n",
    "        from sklearn.model_selection import GridSearchCV\n",
    "        if search_method == 'grid':\n",
    "            optimizer = GridSearchCV(estimator=self.model, param_grid=search_space, scoring=scoring, cv=nFolds, n_jobs=self._n_jobs)\n",
    "        elif search_method =='Bayes':\n",
    "            optimizer = GridSearchCV(estimator=self.model, param_grid=search_space, scoring=scoring, cv=nFolds, n_jobs=self._n_jobs)\n",
    "        else:\n",
    "            optimizer = GridSearchCV(estimator=self.model, param_grid=search_space, scoring=scoring, cv=nFolds, n_jobs=self._n_jobs)\n",
    "\n",
    "        ## fit the Optimizer to the Data\n",
    "        y_reshaped = y.to_numpy().reshape((len(y), ))\n",
    "        optimizer.fit(X, y_reshaped)\n",
    "\n",
    "        ## search results\n",
    "        SearchResults['best_model'] = optimizer.best_estimator_\n",
    "        SearchResults['best_score'] = optimizer.best_score_\n",
    "        SearchResults['best_param'] = SearchResults['best_model'].get_params()\n",
    "        self.HPT_Results[search_method] = SearchResults\n",
    "        \n",
    "        ##\n",
    "        # self.model = optimizer.best_estimator_\n",
    "        if SearchResults['best_param'] is not None:\n",
    "            self.model.set_params(**SearchResults['best_param'])\n",
    "        else:\n",
    "            self.model = self.model\n",
    "\n",
    "        if printLog:\n",
    "            print(f\"\\tThis is the log info\")\n",
    "            print(f\"\\tThe best {scoring}: {SearchResults['best_score']}\")\n",
    "            print(f\"\\tThe optimized Params: {SearchResults['best_param']}\")\n",
    "            ## ----------------------------------------------------------------\n",
    "            print(f\"\\tHyper-parameters Tunning costs time = {(time.time()-beginTime):.2f} s ................\")\n",
    "        return None\n",
    "    \n",
    "    ## <===================== tools =====================>\n",
    "    def _CalcScores(self, y_pred, y_true, printLog=True):   \n",
    "        import numpy as np\n",
    "        dataDict_result = {}\n",
    "        try:\n",
    "            y_pred = y_pred.reshape((len(y_pred), ))\n",
    "            y_true = y_true.reshape((len(y_true), ))\n",
    "        except Exception as e:\n",
    "            print(f\"\\tError! Cannot reformatting the y_pred and y_true when calculating the statistics\")\n",
    "        else:\n",
    "            ## calculate the mean absolute error using Scikit learn\n",
    "            try:\n",
    "                dataDict_result['MAE'] = mean_absolute_error(y_true, y_pred)\n",
    "            except:\n",
    "                dataDict_result['MAE'] = np.nan\n",
    "            \n",
    "            ## calculate the PearsonCorrelationCoefficient\n",
    "            try:\n",
    "                pr_np = np.corrcoef(y_pred, y_true)[1, 0]\n",
    "                dataDict_result['Pearson_R2'] = pr_np * pr_np\n",
    "            except:\n",
    "                dataDict_result['Pearson_R2'] = np.nan\n",
    "\n",
    "            ## calculate the rank-order correlation (Spearman's rho)\n",
    "            try:\n",
    "                sr_sp, sp_sp = spearmanr(y_pred, y_true)[0], spearmanr(y_pred, y_true)[1]\n",
    "                dataDict_result['Spearman_R2'] = sr_sp * sr_sp\n",
    "            except:\n",
    "                dataDict_result['Spearman_R2'], sp_sp = np.nan, np.nan\n",
    "                        \n",
    "            ## calculate the # Kendall's tau\n",
    "            try:\n",
    "                kr_sp, kp_sp = kendalltau(y_pred, y_true)[0] , kendalltau(y_pred, y_true)[1]\n",
    "                dataDict_result['KendallTau_R2'] = kr_sp * kr_sp\n",
    "            except:\n",
    "                dataDict_result['KendallTau_R2'], kp_sp = np.nan, np.nan\n",
    "             \n",
    "            ## print out the results\n",
    "            if printLog:\n",
    "                print(f\"\\t\\tData shape: y_pred {y_pred.shape}; y_true {y_true.shape}\")\n",
    "                print(f\"\\t\\tMean absolute error: {dataDict_result['MAE']:.2f}\")\n",
    "                print(f\"\\t\\tPearson-R2: {dataDict_result['Pearson_R2']:.2f}\")\n",
    "                print(f\"\\t\\tSpearman-R2: {dataDict_result['Spearman_R2']:.2f} (p={sp_sp:.2f})\")\n",
    "                print(f\"\\t\\tKendall-R2: {dataDict_result['KendallTau_R2']:.2f} (p={kp_sp:.2f})\")\n",
    "        return dataDict_result\n",
    "    \n",
    "    def _Plot_Pred_VS_Expt(self, dataTable, label_x='Prediction', label_y='Experiment', color_by=None, diagonal=True, sideHist=True, figTitle=None):\n",
    "        x, y = dataTable[label_x], dataTable[label_y]\n",
    "        ## --------- Start with a square Figure ---------\n",
    "        fig = plt.figure(figsize=(8, 8))\n",
    "\n",
    "        if sideHist:\n",
    "            gs = fig.add_gridspec(2, 2,  width_ratios=(4, 1), height_ratios=(1, 4), left=0.1, right=0.9, bottom=0.1, top=0.9, wspace=0.05, hspace=0.05)\n",
    "            ax = fig.add_subplot(gs[1, 0])\n",
    "            ## --------- add hist ---------\n",
    "            if sideHist:\n",
    "                ax_histx = fig.add_subplot(gs[0, 0], sharex=ax)\n",
    "                ax_histy = fig.add_subplot(gs[1, 1], sharey=ax)\n",
    "\n",
    "                bins = 10\n",
    "                ax_histx.hist(x, bins=bins)\n",
    "                ax_histy.hist(y, bins=bins, orientation='horizontal')\n",
    "            \n",
    "                ax_histx.tick_params(axis=\"x\", labelbottom=False)    # no x labels\n",
    "                ax_histy.tick_params(axis=\"y\", labelleft=False)    # no y labels\n",
    "\n",
    "                ax_histx.tick_params(axis='both', which='major', labelsize=16)\n",
    "                ax_histy.tick_params(axis='both', which='major', labelsize=16)\n",
    "        else:\n",
    "            ax = fig.add_subplot()\n",
    "        \n",
    "        ## --------- add plot ---------\n",
    "        if color_by is None:\n",
    "            ax.scatter(x, y, s=40, alpha=0.5, cmap='Spectral', marker='o')\n",
    "        else:\n",
    "            for i in sorted(dataTable[color_by].unique()):\n",
    "                idx = dataTable[dataTable[color_by]==i].index.to_list()\n",
    "                ax.scatter(x.loc[idx], y.loc[idx], s=40, alpha=0.5, cmap='Spectral', marker='o', label=i)\n",
    "            ax.legend(loc=\"upper left\", title=color_by)    #, bbox_to_anchor=(1.35, 0.5)\n",
    "        \n",
    "        ## figure label and title\n",
    "        ax.set_xlabel(label_x, fontsize=16)\n",
    "        ax.set_ylabel(label_y, fontsize=16)\n",
    "\n",
    "        # now determine nice limits:\n",
    "        # ax_max = np.ceil(max(np.max(x), np.max(y)))\n",
    "        # ax_min = np.floor(min(np.min(x), np.min(y)))\n",
    "        ax_max = max(np.max(x), np.max(y))\n",
    "        ax_min = min(np.min(x), np.min(y))\n",
    "        ax_addon = (ax_max - ax_min)/10\n",
    "        ax_max = ax_max + ax_addon\n",
    "        ax_min = ax_min - ax_addon\n",
    "        ax.set_xlim([ax_min, ax_max])\n",
    "        ax.set_ylim([ax_min, ax_max])\n",
    "        ax.tick_params(axis='both', which='major', labelsize=16)\n",
    "        ax.grid(alpha=0.75)\n",
    "\n",
    "        if diagonal: \n",
    "            diagonalLine = ax.plot([ax_min, ax_max], [ax_min, ax_max], c='lightgray', linestyle='-')\n",
    "            # fold1Line1 = ax.plot([ax_min+1, ax_max], [ax_min, ax_max-1], c='lightgray', linestyle='--')\n",
    "            # fold1Line2 = ax.plot([ax_min, ax_max-1], [ax_min+1, ax_max], c='lightgray', linestyle='--')\n",
    "        \n",
    "        figTitle = f\"Pred vs Expt)\" if figTitle is None else figTitle\n",
    "        fig.suptitle(figTitle, fontsize=24)\n",
    "        return fig\n",
    "\n",
    "    def ___futureFunctionsTBA():\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This is the class of custom ML regression/classification models based on Scikit-learn. \n",
    "\n",
    "'''\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import time\n",
    "import copy\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "##\n",
    "from scipy.stats import linregress, t, pearsonr, spearmanr, kendalltau\n",
    "\n",
    "# from skopt import BayesSearchCV\n",
    "from sklearn.metrics import mean_absolute_error, roc_auc_score, auc, roc_curve, accuracy_score, RocCurveDisplay\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "## custom modules\n",
    "\n",
    "\n",
    "    def PostProcess_y(self, dataTable_y):\n",
    "        assert len(dataTable_y.columns) == 1, f\"Error! The <dataTable_y> has incorrect {len(y.columns)} columns: {y.columns}\"\n",
    "        colName_raw = dataTable_y.columns[0]\n",
    "        y = copy.deepcopy(dataTable_y)\n",
    "\n",
    "        if self.transformType=='log10':\n",
    "            y['y_postprocess'] = y[colName_raw].apply(lambda x: 10**(x))\n",
    "        \n",
    "        elif self.transformType=='One-hot':\n",
    "            y['y_postprocess'] = y[colName_raw].apply(lambda x: dataDict_b2v(str(x)))\n",
    "        else:\n",
    "            y['y_postprocess'] = y[colName_raw].apply(lambda x: x)\n",
    "        return y\n",
    "    ## ============================================================\n",
    "\n",
    "\n",
    "\n",
    "#########################################################################################\n",
    "############################### Classification model ####################################\n",
    "#########################################################################################\n",
    "class Classification_Model(object):\n",
    "    ## <===================== model initiation =====================>\n",
    "    def __init__(self, myScikitModel=None, modelName='Classification_Model', rng=666666, n_jobs=-1):\n",
    "        assert myScikitModel is not None, f\"\\tWarning! Please define an initiated RDKit ML model\"\n",
    "        self._name = modelName\n",
    "        self._rng = rng\n",
    "        self._n_jobs = n_jobs\n",
    "        self.model = myScikitModel\n",
    "        self.HPT_Results = {}\n",
    "        self.predictions = None\n",
    "        self.performance = {}\n",
    "        self.plots = {}\n",
    "        self.best_threshold = 0.5\n",
    "        self.class_label = {0: \"0\", 1: \"0\"}\n",
    "\n",
    "    ## <===================== model training =====================>\n",
    "    def Train(self, X, y, printLog=True, HPT=False, search_space=None):\n",
    "        ## count time\n",
    "        beginTime = time.time()\n",
    "        ## ----------------------------------------------------------------\n",
    "        ## ------------ hyper parameter search ------------\n",
    "        if HPT:\n",
    "            self._HyperParamSearch(X, y, search_space=search_space, printLog=printLog)\n",
    "        \n",
    "        ## ------------ fit the model ------------\n",
    "        self.model.fit(X, y)\n",
    "       \n",
    "        ## ----------------------------------------------------------------\n",
    "        print(f\"\\tModel construction costs time = {(time.time()-beginTime):.2f} s ................\")\n",
    "        return None\n",
    "\n",
    "    ## <===================== model evaluation =====================>\n",
    "    def MakePrediction(self, X):\n",
    "        y_pred_prob = self.model.predict_proba(X)[:, 1]\n",
    "        y_pred = np.where(y_pred_prob >= self.best_threshold, 1, 0)\n",
    "        return y_pred, y_pred_prob\n",
    "    \n",
    "    def Evaluate(self, X, y, ds_label='TBD', estCutoff=False, printLog=True, plotResult=False):\n",
    "        ## make prediction\n",
    "        # y_pred = self.model.predict(X)    #####################\n",
    "        _, y_pred_prob = self.model.predict_proba(X)[:, 1]\n",
    "        \n",
    "        ## calcualte statistics\n",
    "        print(f\"\\tEvaluation results of the {ds_label} dataset:\")\n",
    "        self.performance[ds_label] = self._CalcScores(y_pred_prob=y_pred_prob, y_true=y.to_numpy(), estTrsd=estCutoff, printLog=printLog)\n",
    "\n",
    "        ## save prediction\n",
    "        df_predictions = copy.deepcopy(y)\n",
    "        df_predictions['Experiment'] = df_predictions[y.columns[0]]\n",
    "        df_predictions['DataSet'] = ds_label\n",
    "        df_predictions['Prob_1'] = y_pred_prob\n",
    "        df_predictions['Prediction'] = df_predictions['Prob_1'].apply(lambda x: self._Pred_Class(x))\n",
    "        self.predictions = pd.concat([self.predictions, df_predictions]) if self.predictions is not None else df_predictions\n",
    "        \n",
    "        ## plotting\n",
    "        if plotResult:\n",
    "            self.plots[ds_label] = self._Plot_ROCAUC(ds_label)\n",
    "        return None\n",
    "\n",
    "    ## <===================== HPTunning =====================>\n",
    "    def _HyperParamSearch(self, X, y, search_space=None, search_method='grid', scoring='roc_auc', nFolds=5, printLog=True):\n",
    "        ## count time\n",
    "        beginTime = time.time()\n",
    "        ## --------------------------------\n",
    "        print(f\"\\tStart Hyper-Parameter Tunning ...\")\n",
    "        SearchResults = {'best_model': None, 'best_score':None, 'best_param':None}\n",
    "        \n",
    "        ##\n",
    "        if search_method == 'grid':\n",
    "            optimizer = GridSearchCV(estimator=self.model, param_grid=search_space, scoring=scoring, cv=nFolds, n_jobs=self._n_jobs)\n",
    "        elif search_method =='Bayes':\n",
    "            optimizer = GridSearchCV(estimator=self.model, param_grid=search_space, scoring=scoring, cv=nFolds, n_jobs=self._n_jobs)\n",
    "        else:\n",
    "            optimizer = GridSearchCV(estimator=self.model, param_grid=search_space, scoring=scoring, cv=nFolds, n_jobs=self._n_jobs)\n",
    "\n",
    "        ## fit the Optimizer to the Data\n",
    "        y_reshaped = y.to_numpy().reshape((len(y), ))\n",
    "        optimizer.fit(X, y_reshaped)\n",
    "\n",
    "        ## search results\n",
    "        SearchResults['best_model'] = optimizer.best_estimator_\n",
    "        SearchResults['best_score'] = optimizer.best_score_\n",
    "        SearchResults['best_param'] = SearchResults['best_model'].get_params()\n",
    "        self.HPT_Results[search_method] = SearchResults\n",
    "        \n",
    "        ##\n",
    "        # self.model = optimizer.best_estimator_\n",
    "        if SearchResults['best_param'] is not None:\n",
    "            self.model.set_params(**SearchResults['best_param'])\n",
    "        else:\n",
    "            self.model = self.model\n",
    "\n",
    "        if printLog:\n",
    "            print(f\"\\tThis is the log info\")\n",
    "            print(f\"\\tThe best {scoring}: {SearchResults['best_score']}\")\n",
    "            print(f\"\\tThe optimized Params: {SearchResults['best_param']}\")\n",
    "            ## ----------------------------------------------------------------\n",
    "            print(f\"\\tHyper-parameters Tunning costs time = {(time.time()-beginTime):.2f} s ................\")\n",
    "        return None\n",
    "    \n",
    "    ## <===================== tools =====================>    \n",
    "    def __CalcScore_ROCAUC(self, y_prob, y_true, estTrsd=False):\n",
    "        try:\n",
    "            ## Assuming y_true are the true labels and y_prob are the predicted probabilities\n",
    "            fpr, tpr, thresholds = roc_curve(y_true, y_prob)\n",
    "            aucs_score = auc(fpr, tpr)\n",
    "\n",
    "            ## determine the best threshold\n",
    "            if estTrsd:\n",
    "                ## Calculate the distance to the top-left corner (0,1)\n",
    "                distances = np.sqrt(fpr**2 + (1-tpr)**2)\n",
    "                self.best_threshold = thresholds[distances.argmin()]\n",
    "                print(f\"\\tThe best threshold is changged to {self.best_threshold}\")\n",
    "                # ## Calculate Youden's J statistic\n",
    "                # youden_j = tpr - fpr\n",
    "                # self.best_threshold = thresholds[youden_j.argmax()]\n",
    "        except Exception as e:\n",
    "            print(f'Warning! Cannot calculate ROC AUC, error msg: {e}')\n",
    "            auc_score, fpr, tpr, thresholds = np.nan, np.nan, np.nan, np.nan\n",
    "        results = {'auc_score': aucs_score, 'fpr': fpr, 'tpr': tpr, 'thresholds': thresholds}\n",
    "        return results\n",
    "\n",
    "    def __CalcScore_ACC(self, y_pred, y_true):\n",
    "        try:\n",
    "            acc = accuracy_score(y_true, y_pred)\n",
    "        except Exception as e:\n",
    "            acc = np.nan\n",
    "        return acc\n",
    "    \n",
    "    def __CalcScore_CM(self, y_pred, y_true):\n",
    "        try:\n",
    "            cm = confusion_matrix(Clas_test, Clas_test_pred)\n",
    "        except Exception as e:\n",
    "            cm = np.nan\n",
    "        return cm\n",
    "                \n",
    "    def _CalcScores(self, y_pred_prob, y_true, estTrsd=False, printLog=True):   \n",
    "        dataDict_result = {}\n",
    "        try:\n",
    "            y_pred = y_pred.reshape((len(y_pred), ))\n",
    "            y_true = y_true.reshape((len(y_true), ))\n",
    "        except Exception as e:\n",
    "            print(f\"\\tError! Cannot reformatting the y_pred and y_true when calculating the statistics\")\n",
    "        else:\n",
    "            ## calculate the ROC auc\n",
    "            dataDict_result['ROC_AUC'] = self.__CalcScore_ROCAUC(y_pred, y_true, estTrsd=estTrsd)\n",
    "            \n",
    "            ## calculate the accuracy\n",
    "            y_pred_binary = np.where(y_pred_prob >= self.best_threshold, 1, 0)\n",
    "            dataDict_result['Accuracy'] = self.__CalcScore_ACC(y_pred=y_pred_binary, y_true=y_true)\n",
    "            dataDict_result['ConfusionMatrics'] = self.__CalcScore_CM(y_pred=y_pred_binary, y_true=y_true)\n",
    "             \n",
    "            ## print out the results\n",
    "            if printLog:\n",
    "                print(f\"\\t\\tData shape: y_pred {y_pred.shape}; y_true {y_true.shape}\")\n",
    "                print(f\"\\t\\tAUROC: {dataDict_result['ROC_AUC']['auc_score']:.2f}\")\n",
    "                print(f\"\\t\\tAccuracy: {dataDict_result['Accuracy']:.2f}\")\n",
    "                print(f\"\\t\\tConfusionMatrics: {dataDict_result['ConfusionMatrics']}\")\n",
    "        return dataDict_result\n",
    "\n",
    "    def _Plot_ROCAUC(self, ds_label):\n",
    "        ## initiate the figure axes\n",
    "        fig, ax = plt.subplots(figsize=(6, 6))\n",
    "        ## generate plot\n",
    "        try:\n",
    "            dataDict_roc = self.performance[ds_label]['ROC_AUC']\n",
    "            fpr, tpr, roc_auc = dataDict_roc['fpr'], dataDict_roc['tpr'], dataDict_roc['auc_score']\n",
    "            display = RocCurveDisplay(fpr=fpr, tpr=tpr, roc_auc=roc_auc, estimator_name=ds_label)\n",
    "        except Exception as e:\n",
    "            pass\n",
    "        else:\n",
    "            display.plot(ax=ax)\n",
    "            ## set the figure config\n",
    "            ax.set(xlim=[-0.05, 1.05], ylim=[-0.05, 1.05], \n",
    "                xlabel=\"False Positive Rate\", ylabel=\"True Positive Rate\", \n",
    "                title=f\"ROC Curve ({ds_label})\")\n",
    "            ax.axis(\"square\")\n",
    "            ax.legend(loc=\"lower right\")\n",
    "            # plt.show()\n",
    "        return fig\n",
    "    \n",
    "    def _Pred_Class(self, prob):\n",
    "        if prob >= self.best_threshold:\n",
    "            pred = 1 \n",
    "        else:\n",
    "            pred = 0\n",
    "        return pred\n",
    "\n",
    "    def ___futureFunctionsTBA():\n",
    "        return None\n",
    "\n",
    "#########################################################################################\n",
    "################################# select_ML_methods #####################################\n",
    "#########################################################################################\n",
    "\n",
    "def select_ML_methods(modelType, ml_methed, rng=666666, knnk=3, n_jobs=-1):\n",
    "    if modelType == 'regression':\n",
    "        if ml_methed == 'RF':\n",
    "            from sklearn.ensemble import RandomForestRegressor\n",
    "            sk_model = RandomForestRegressor(random_state=rng, oob_score=True, n_jobs=n_jobs)\n",
    "            search_space = {\n",
    "                'n_estimators': [50, 100, 250, 500],\n",
    "                'max_depth': [2, 4, 6],\n",
    "                'max_features': ['auto', 'sqrt'],\n",
    "                'min_samples_leaf': [1, 5, 10, 25, 50],\n",
    "                'max_features': ['sqrt', 'log2', None],\n",
    "                'min_samples_split': [2, 5, 8, 10]}\n",
    "        \n",
    "        elif ml_methed == 'linear':\n",
    "            from sklearn.linear_model import LinearRegression\n",
    "            sk_model = LinearRegression(n_jobs=n_jobs)\n",
    "            search_space = None\n",
    "            # from sklearn.linear_model import Lasso\n",
    "            # sk_model = Lasso(alpha=0.1)\n",
    "            # search_space = {'alpha': [0, 0.1, 0.25, 0.5, 0.8]}\n",
    "        \n",
    "        elif ml_methed == 'SVM':\n",
    "            from sklearn.svm import SVR\n",
    "            sk_model = SVR(kernel=\"rbf\", gamma=0.1)\n",
    "            search_space = {\n",
    "                'kernel': ['poly', 'rbf', 'sigmoid'], \n",
    "                'gamma': ['scale', 'auto'], \n",
    "                'C': [0.1, 1, 10, 100]}\n",
    "        \n",
    "        elif ml_methed == 'MLP':\n",
    "            from sklearn.neural_network import MLPRegressor\n",
    "            sk_model = MLPRegressor(random_state=rng, max_iter=500, early_stopping=True)\n",
    "            search_space = {\n",
    "                'hidden_layer_sizes': [(128,), (128, 128), (128, 128, 128)], \n",
    "                'activation': ['logistic', 'tanh', 'relu'], \n",
    "                'solver': ['sgd', 'adam'],\n",
    "                'alpha': [0.1, 0.01, 0.001, 0.0001]}\n",
    "        \n",
    "        elif ml_methed == 'KNN':\n",
    "            from sklearn.neighbors import KNeighborsRegressor\n",
    "            sk_model = KNeighborsRegressor(n_neighbors=knnk, n_jobs=n_jobs)\n",
    "            search_space = {'n_neighbors': [1, 3, 5, 10]}\n",
    "        \n",
    "        else:\n",
    "            print(f\"Error! no proper ML methods were selected, using Linear method instead\")\n",
    "            from sklearn.linear_model import Lasso\n",
    "            sk_model = Lasso(alpha=0.1)\n",
    "            search_space = {'alpha': [0, 0.1, 0.25, 0.5, 0.8]}\n",
    "\n",
    "    elif modelType == 'classification':\n",
    "        if ml_methed == 'RF':\n",
    "            from sklearn.ensemble import RandomForestClassifier\n",
    "            sk_model = RandomForestClassifier(random_state=rng, class_weight='balanced_subsample', oob_score=True, n_jobs=n_jobs)\n",
    "            search_space = {\n",
    "                'n_estimators': [50, 100, 250, 500],\n",
    "                'max_depth': [2, 4, 6],\n",
    "                'max_features': ['auto', 'sqrt'],\n",
    "                'min_samples_leaf': [1, 5, 10, 25, 50],\n",
    "                'max_features': ['sqrt', 'log2', None],\n",
    "                'min_samples_split': [2, 5, 8, 10]}\n",
    "\n",
    "        elif ml_methed == 'linear':\n",
    "            from sklearn.linear_model import LogisticRegression\n",
    "            sk_model = LogisticRegression(random_state=rng, n_jobs=n_jobs)\n",
    "            search_space = None\n",
    "\n",
    "        elif ml_methed == 'SVM':\n",
    "            from sklearn.svm import SVC\n",
    "            sk_model = SVC(kernel=\"rbf\", gamma=0.1, random_state=rng, probability=True)\n",
    "            search_space = {\n",
    "                'kernel': ['poly', 'rbf', 'sigmoid'], \n",
    "                'gamma': ['scale', 'auto'], \n",
    "                'C': [0.1, 1, 10, 100]}\n",
    "\n",
    "        elif ml_methed == 'MLP':\n",
    "            from sklearn.neural_network import MLPClassifier\n",
    "            sk_model = MLPClassifier(random_state=rng, max_iter=500, early_stopping=True)\n",
    "            search_space = {\n",
    "                'hidden_layer_sizes': [(128,), (128, 128), (128, 128, 128)], \n",
    "                'activation': ['logistic', 'tanh', 'relu'], \n",
    "                'solver': ['sgd', 'adam'],\n",
    "                'alpha': [0.1, 0.01, 0.001, 0.0001]}\n",
    "        \n",
    "        elif ml_methed == 'XGBoost':\n",
    "            from sklearn.ensemble import GradientBoostingClassifier\n",
    "            sk_model = GradientBoostingClassifier(n_estimators=100, random_state=rng)\n",
    "            search_space = {\n",
    "                'n_estimators': [50, 100, 250, 500],\n",
    "                'loss': [\"log_loss\", \"exponential\"],\n",
    "                'max_depth': [1, 3, 5],\n",
    "                'learning_rate': [0.01, 0.1, 1],\n",
    "                'min_samples_leaf': [1, 5, 10, 25, 50],\n",
    "                'min_samples_split': [2, 5, 8, 10],\n",
    "                'max_features': ['sqrt', 'log2', None]}\n",
    "        \n",
    "        elif ml_methed == 'KNN':\n",
    "            from sklearn.neighbors import KNeighborsClassifier\n",
    "            sk_model = KNeighborsClassifier(n_neighbors=knnk, n_jobs=n_jobs)\n",
    "            search_space = {'n_neighbors': [1, 3, 5, 10]}\n",
    "\n",
    "    else:\n",
    "        print(f\"\\tError! ML model type should be one of <regression> or <classification>\" )\n",
    "    return sk_model, search_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
