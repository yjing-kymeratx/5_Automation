{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
<<<<<<< HEAD
    "import copy\n",
    "import pickle\n",
    "import chardet\n",
    "import sqlite3\n",
    "import subprocess\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from rdkit import Chem"
=======
    "import chardet\n",
    "import subprocess\n",
    "import pandas as pd"
>>>>>>> 4e14183d906f40846fab9a0c104609029a22b9e6
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 5,
=======
   "execution_count": 2,
>>>>>>> 4e14183d906f40846fab9a0c104609029a22b9e6
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################################################\n",
    "##################################### Custom Tools ###########################################\n",
    "##############################################################################################\n",
<<<<<<< HEAD
    "def _determine_encoding(dataFile):\n",
=======
    "def determine_encoding(dataFile):\n",
>>>>>>> 4e14183d906f40846fab9a0c104609029a22b9e6
    "    # Step 1: Open the CSV file in binary mode\n",
    "    with open(dataFile, 'rb') as f:\n",
    "        data = f.read()\n",
    "    # Step 2: Detect the encoding using the chardet library\n",
    "    encoding_result = chardet.detect(data)\n",
    "    # Step 3: Retrieve the encoding information\n",
    "    encoding = encoding_result['encoding']\n",
    "    # Step 4: Print/export the detected encoding information\n",
    "    # print(\"Detected Encoding:\", encoding)\n",
    "    return encoding\n",
    "\n",
<<<<<<< HEAD
    "def _defineOutputFolder(fileName_out):\n",
=======
    "def defineOutputFolder(fileName_out):\n",
>>>>>>> 4e14183d906f40846fab9a0c104609029a22b9e6
    "    if fileName_out is None:\n",
    "        fileName_out = os.path.join(os.getcwd(), 'MMPs_results')\n",
    "    \n",
    "    os.makedirs(fileName_out) if not os.path.exists(fileName_out) else print(f'\\t---->{fileName_out} is existing')\n",
    "    return fileName_out\n",
    "\n",
    "##############################################################################################\n",
    "########################### Load original csv for MMPs analysis ##############################\n",
    "##############################################################################################\n",
    "def CSV_loader(fileName_in, colName_mid, colName_smi, colNames_activity, sep=','):\n",
    "    print(f\"1. Loading csv from {fileName_in}\")\n",
    "    assert os.path.exists(fileName_in), f\"File {fileName_in} does not exist\"\n",
    "    ##\n",
<<<<<<< HEAD
    "    encoding = _determine_encoding(fileName_in)\n",
=======
    "    encoding = determine_encoding(fileName_in)\n",
>>>>>>> 4e14183d906f40846fab9a0c104609029a22b9e6
    "    ##\n",
    "    dataTable_raw = pd.read_csv(fileName_in, sep=sep, encoding=encoding)\n",
    "    print(f\"\\tThe original csv file has {dataTable_raw.shape[0]} rows and {dataTable_raw.shape[1]} columns\")\n",
    "    print(f\"\\tColumn for compound ID is {colName_mid}\")\n",
    "    print(f\"\\tColumn for compound SMILES is {colName_smi}\")\n",
    "\n",
    "    colName_prop_list = colNames_activity.split(',')\n",
    "    print(f\"\\tColumns for compound activity includes {colName_prop_list}\")\n",
    "    for prop_name in colName_prop_list:\n",
    "        if prop_name not in dataTable_raw.columns:\n",
    "            print(f\"\\t---->Warning! {prop_name} is not in the csv file, pls check ...\")\n",
    "            colName_prop_list.remove(prop_name)\n",
    "    ##\n",
    "    dataTable_raw = dataTable_raw.dropna(subset=[colName_mid, colName_smi]).reset_index(drop=True)\n",
    "    print(f\"\\tThere are total {dataTable_raw.shape[0]} molecules in the csv with Structure(SMILES)\")\n",
    "\n",
    "    return dataTable_raw, colName_prop_list\n",
    "\n",
    "##############################################################################################\n",
    "######################## Prepare .smi and csv for MMPs analysis ##############################\n",
    "##############################################################################################\n",
    "def Smiles_Prep(dataTable_raw, colName_mid, colName_smi, colName_prop_list, fileName_out):\n",
<<<<<<< HEAD
    "    print(f\"2. Prepare the smi & prop file for MMPs-DB analysis\")\n",
=======
    "    print(f\"2. Fragment the SMILES\")\n",
>>>>>>> 4e14183d906f40846fab9a0c104609029a22b9e6
    "    ## the SMILES file for fragmentation\n",
    "    file_smi = f'{fileName_out}/Compounds_All.smi'\n",
    "    file_prop_csv = f'{fileName_out}/Property_All.csv'\n",
    "    delimiter = ' '\n",
    "\n",
    "    data_dict_prop = {}\n",
    "    with open(file_smi, \"w\") as output_file:\n",
    "        # output_file.write(f'SMILES{delimiter}ID' + \"\\n\")\n",
    "        for idx in dataTable_raw.index:\n",
    "            mol_id = dataTable_raw[colName_mid][idx]\n",
    "            mol_smi = dataTable_raw[colName_smi][idx]\n",
    "\n",
    "            ## prepare the SMILES output\n",
    "            this_line = f'{mol_smi}{delimiter}{mol_id}'\n",
    "            output_file.write(this_line + \"\\n\")  # Add a newline character after each string\n",
    "\n",
    "            ## prepare the property CSV output\n",
    "            data_dict_prop[idx] = {}\n",
    "            data_dict_prop[idx]['ID'] = mol_id\n",
    "\n",
    "            for prop_name in colName_prop_list:\n",
    "                try:\n",
    "                    if dataTable_raw[prop_name].notna()[idx]:\n",
    "                        mol_prop = float(dataTable_raw[prop_name][idx])\n",
    "                    else:\n",
    "                        mol_prop = \"*\"\n",
    "                except Exception as e:\n",
    "                    data_dict_prop[idx][prop_name] = \"*\"\n",
    "                    print(f'\\t---->Warning! This mol {mol_id} does not have a proper property value: {e}')\n",
    "                else:\n",
    "                    data_dict_prop[idx][prop_name] = mol_prop\n",
    "        print(f'\\tThe SMILES strings have been saved into .smi file: {file_smi}')\n",
    "        \n",
    "    ## save the csv results\n",
    "    data_table_prop = pd.DataFrame.from_dict(data_dict_prop).T\n",
    "    data_table_prop.to_csv(file_prop_csv, index=False, sep=delimiter)\n",
    "    print(f'\\tThe property data have been saved into .csv file: {file_smi}')\n",
    "    return file_smi, file_prop_csv\n",
    "\n",
    "##############################################################################################\n",
    "##################################### Fragment the SMILES ####################################\n",
    "##############################################################################################\n",
    "def Smiles_fragmentation(fileName_out, file_smi):\n",
<<<<<<< HEAD
    "    print(f\"3. Fragment the SMILES\")\n",
=======
    "    \n",
>>>>>>> 4e14183d906f40846fab9a0c104609029a22b9e6
    "    file_fragdb = f'{fileName_out}/Compounds_All.fragdb'\n",
    "    commandLine = ['mmpdb', 'fragment', file_smi, '-o', file_fragdb]\n",
    "    process = subprocess.Popen(commandLine, stdout=subprocess.PIPE)\n",
    "    output, error = process.communicate()\n",
    "    print(f'\\tThe fragmentation is completed and saved into file {file_fragdb}')\n",
    "    return file_fragdb\n",
    "\n",
    "##############################################################################################\n",
    "################## Indexing to find the MMPs and load the activity data ######################\n",
    "##############################################################################################\n",
    "def Index_LinkActivity(fileName_out, file_fragdb, file_prop_csv):\n",
<<<<<<< HEAD
    "    print(f\"4.1 Indexing to find the matched molecular pairs in the fragment file\")\n",
    "    print(f\"4.2 Now load the activity/property data\")\n",
=======
    "    print(f\"3. Indexing to find the matched molecular pairs in the fragment file\")\n",
    "    print(f\"4. Now load the activity/property data\")\n",
>>>>>>> 4e14183d906f40846fab9a0c104609029a22b9e6
    "    file_mmpdb = f'{fileName_out}/Compounds_All.mmpdb'\n",
    "    commandLine = ['mmpdb', 'index', file_fragdb, '-o', file_mmpdb, '--properties', file_prop_csv]\n",
    "    process = subprocess.Popen(commandLine, stdout=subprocess.PIPE)\n",
    "    output, error = process.communicate()\n",
    "    print(f'\\tThe indexing/mmp generation is completed and saved into file {file_mmpdb}')\n",
    "    return file_mmpdb\n",
    "\n",
    "##############################################################################################\n",
    "############################### Loading data from database ###################################\n",
    "##############################################################################################\n",
<<<<<<< HEAD
    "def _call_my_query(db_file, my_query):\n",
=======
    "def call_my_query(db_file, my_query):\n",
>>>>>>> 4e14183d906f40846fab9a0c104609029a22b9e6
    "    ## connect to the SQLIte database\n",
    "    my_connection = sqlite3.connect(db_file)\n",
    "\n",
    "    ## create a cursor object\n",
    "    my_cursor = my_connection.cursor()\n",
    "\n",
    "    ## excute the query\n",
    "    my_cursor.execute(my_query)\n",
    "\n",
    "    ## fetch all the rows\n",
    "    rows = my_cursor.fetchall()\n",
    "    \n",
    "    ## export the results\n",
    "    data_list = [row for row in rows]\n",
    "\n",
    "    my_connection.close()\n",
    "    return data_list\n",
    "\n",
<<<<<<< HEAD
    "def _extract_tables(db_file, table_name):\n",
    "    ## extract table data from SQLite DB\n",
    "    my_query_colName = f\"PRAGMA table_info({table_name})\"\n",
    "    colName_list = _call_my_query(db_file, my_query_colName)\n",
    "\n",
    "    my_query_data = f\"SELECT * FROM {table_name}\"\n",
    "    data_list = _call_my_query(db_file, my_query_data)\n",
=======
    "def extract_tables(db_file, table_name):\n",
    "    ## extract table data from SQLite DB\n",
    "    my_query_colName = f\"PRAGMA table_info({table_name})\"\n",
    "    colName_list = call_my_query(db_file, my_query_colName)\n",
    "\n",
    "    my_query_data = f\"SELECT * FROM {table_name}\"\n",
    "    data_list = call_my_query(db_file, my_query_data)\n",
>>>>>>> 4e14183d906f40846fab9a0c104609029a22b9e6
    "\n",
    "    ## clean up data\n",
    "    dataDict = {}\n",
    "    for row_tuple in data_list:\n",
    "        idx = row_tuple[0]\n",
    "        dataDict[idx] = {}\n",
    "\n",
    "        for col in colName_list:\n",
    "            colIdx, colName = col[0], col[1]\n",
    "            dataDict[idx][colName] = row_tuple[colIdx]\n",
    "    return dataDict\n",
    "    \n",
<<<<<<< HEAD
    "def DataExtractionFromDB(file_mmpdb, folderName_tmp, savedict=False):\n",
    "    print(f\"5. Now extracting tables from MMPs database\")\n",
    "    dataDict_tables = {}\n",
    "    for table_name in [\"pair\", \"compound\", \"compound_property\", \"property_name\", \"constant_smiles\",\n",
    "                    \"rule\", \"rule_smiles\", \"rule_environment\", \"rule_environment_statistics\", \"environment_fingerprint\"]:\n",
    "        dataDict_table = _extract_tables(file_mmpdb, table_name)\n",
    "        dataTable_table = pd.DataFrame.from_dict(dataDict_table).T\n",
    "\n",
    "        ## output\n",
    "        subFolderDB = f\"{folderName_tmp}/DB_tables\"\n",
    "        os.makedirs(subFolderDB) if not os.path.exists(subFolderDB) else print(f'\\t---->{subFolderDB} is existing')\n",
    "        table_out = f\"{subFolderDB}/DB_table_{table_name}.csv\"\n",
    "        dataTable_table.to_csv(table_out, index=False)\n",
    "        print(f\"\\t<{table_name}> table has been saved into {table_out}\")\n",
    "        dataDict_tables[table_name] = dataTable_table\n",
    "        # print(table_name)\n",
    "    \n",
    "    if savedict:\n",
    "        tableDict_out = f\"{subFolderDB}/DB_table_all.dict\"\n",
    "        with open(tableDict_out, \"wb\") as ofh:\n",
    "            pickle.dump(dataDict_tables, ofh)\n",
    "            print(f\"\\tAll tables have been dumped into {tableDict_out}\")\n",
    "    return dataDict_tables\n",
    "\n",
    "##############################################################################################\n",
    "############################### Loading data from database ###################################\n",
    "##############################################################################################\n",
    "def _findPropValue(dbTable_propValue, cid, prop_id, average=False):\n",
    "    cond_1 = (dbTable_propValue[\"compound_id\"]==cid)\n",
    "    cond_2 = (dbTable_propValue[\"property_name_id\"]==prop_id)\n",
    "    \n",
    "    match_data = dbTable_propValue[cond_1 & cond_2][\"value\"].values\n",
    "\n",
    "    if match_data.shape[0] <= 0:\n",
    "        result = np.nan\n",
    "    else:\n",
    "        if average:\n",
    "            if match_data.shape[0] > 1:\n",
    "                print(f\"\\t\\tWarning! Compound {cid} has multiple <{prop_id}> values\")\n",
    "                result = np.meam(match_data)\n",
    "            else:\n",
    "                result = match_data[0]\n",
    "        else:\n",
    "            result = np.array2string(match_data, separator=',')\n",
    "    return result\n",
    "\n",
    "def MMPs_DataClean(dataDict_tables, add_symetric=True):\n",
    "    print(f\"6. Now clean up the MMPs data and export a table of pairs\")\n",
    "    ## get the individual database Tables\n",
    "    dataTable_pair = dataDict_tables[\"pair\"]\n",
    "    dbTable_cmpd = dataDict_tables[\"compound\"]\n",
    "    dbTable_propName = dataDict_tables[\"property_name\"]\n",
    "    dbTable_propValue = dataDict_tables[\"compound_property\"]\n",
    "\n",
    "    ## ------------- build the dataDict of pairs -------------\n",
    "    print(f\"\\tNow start cleanning up the dataDict of pairs ...\")\n",
    "    dataDict = {}\n",
    "    for idx in dataTable_pair.index:\n",
    "        pair_idx = dataTable_pair['id'][idx]\n",
    "        cid_1 = dataTable_pair['compound1_id'][idx]\n",
    "        cid_2 = dataTable_pair['compound2_id'][idx]\n",
    "        const_id = dataTable_pair['constant_id'][idx]\n",
    "        rule_env_id = dataTable_pair['rule_environment_id'][idx]\n",
    "\n",
    "        ## initialize the sub-dict\n",
    "        pair_info = f\"{cid_1}==>{cid_2}\"\n",
    "        if pair_info not in dataDict:\n",
    "            ## add pair basic info\n",
    "            dataDict[pair_info] = {}\n",
    "            dataDict[pair_info][\"pair_info\"] = pair_info\n",
    "            dataDict[pair_info][\"pair_id\"] = f\"({min([cid_1, cid_2])},{max([cid_1, cid_2])})\"\n",
    "            dataDict[pair_info][\"compound1_id\"] = cid_1\n",
    "            dataDict[pair_info][\"compound2_id\"] = cid_2\n",
    "            dataDict[pair_info][\"pair_detail\"] = {}\n",
    "\n",
    "            ## add compound info\n",
    "            dataDict[pair_info][\"KT_id_1\"] = dbTable_cmpd['public_id'][cid_1]\n",
    "            dataDict[pair_info][\"KT_id_2\"] = dbTable_cmpd['public_id'][cid_2]\n",
    "            dataDict[pair_info][\"Smiles_1\"] = dbTable_cmpd['input_smiles'][cid_1]\n",
    "            dataDict[pair_info][\"Smiles_2\"] = dbTable_cmpd['input_smiles'][cid_2]\n",
    "\n",
    "            ## add compound prop info\n",
    "            for prop_id in dbTable_propName.index:\n",
    "                prop_name = dbTable_propName['name'][prop_id]\n",
    "\n",
    "                dataDict[pair_info][f\"{prop_name}_1\"] = _findPropValue(dbTable_propValue, cid_1, prop_id, average=True)\n",
    "                dataDict[pair_info][f\"{prop_name}_2\"] = _findPropValue(dbTable_propValue, cid_2, prop_id, average=True)\n",
    "\n",
    "        ## add pair details information (constant part)\n",
    "        if const_id not in dataDict[pair_info][\"pair_detail\"]:\n",
    "            dataDict[pair_info][\"pair_detail\"][const_id] = []\n",
    "        \n",
    "        ## add pair details information (rule_env)\n",
    "        if rule_env_id not in dataDict[pair_info][\"pair_detail\"][const_id]:\n",
    "            dataDict[pair_info][\"pair_detail\"][const_id].append(rule_env_id)\n",
    "\n",
    "    print(f\"\\t\\tOriginal num_pairs in dataDict: {len(dataDict)}\")\n",
    "    \n",
    "    ## ------------- add the symetric pairs if not exist -------------\n",
    "    if add_symetric:\n",
    "        print(f\"\\t\\tNow adding symetric pairs ...\")\n",
    "        list_pair_info_4loop = copy.deepcopy(list(dataDict.keys()))\n",
    "        list_pair_info_4check = copy.deepcopy(list(dataDict.keys()))\n",
    "        for pair_info in list_pair_info_4loop:\n",
    "            if pair_info in list_pair_info_4check:\n",
    "                list_pair_info_4check.remove(pair_info)\n",
    "\n",
    "                ## reverse pair\n",
    "                cid_1, cid_2 = pair_info.split(\"==>\")\n",
    "                pair_info_revs = f\"{cid_2}==>{cid_1}\"\n",
    "                if pair_info_revs in list_pair_info_4check:\n",
    "                    list_pair_info_4check.remove(pair_info_revs)\n",
    "                else:\n",
    "                    ## if reversed pair not in check list, add it in the dict\n",
    "                    dataDict[pair_info_revs] = {}\n",
    "                    dataDict[pair_info_revs][\"pair_info\"] = pair_info_revs\n",
    "                    dataDict[pair_info_revs][\"pair_id\"] = dataDict[pair_info][\"pair_id\"]\n",
    "                    dataDict[pair_info_revs][\"pair_detail\"] = {key: [] for key in dataDict[pair_info][\"pair_detail\"]}\n",
    "\n",
    "                    for tmp_key in dataDict[pair_info]:\n",
    "                        if '1' in tmp_key:\n",
    "                            dataDict[pair_info_revs][tmp_key] = dataDict[pair_info][tmp_key.replace('1', '2')]\n",
    "                        elif '2' in tmp_key:\n",
    "                            dataDict[pair_info_revs][tmp_key] = dataDict[pair_info][tmp_key.replace('2', '1')]\n",
    "                        else:\n",
    "                            pass\n",
    "            else:\n",
    "                ## this pair was removed from check list because it's the revs pair of another pair\n",
    "                pass\n",
    "        print(f\"\\t\\tNew num_pairs in symetric dataDict: {len(dataDict)}\")\n",
    "    return dataDict\n",
    "\n",
=======
>>>>>>> 4e14183d906f40846fab9a0c104609029a22b9e6
    "##############################################################################################\n",
    "############################### Loading data from database ###################################\n",
    "##############################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t---->/mnt/data0/Research/5_Automation/mmp/rdkit/Application_MMPsAnalysis/MMPs_results is existing\n"
     ]
    }
   ],
   "source": [
    "##############################################################################################\n",
    "########################### argument  original csv for MMPs analysis ##############################\n",
    "##############################################################################################\n",
<<<<<<< HEAD
=======
    "\n",
>>>>>>> 4e14183d906f40846fab9a0c104609029a22b9e6
    "fileName_in = f'./Data_ADMET_4_MMP_2024Aug27.csv'    ## input CSV\n",
    "sep = ','\n",
    "\n",
    "fileName_out = None    # output folder\n",
<<<<<<< HEAD
    "fileName_out = _defineOutputFolder(fileName_out)\n",
    "\n",
    "colName_mid = 'Compound Name'\n",
    "colName_smi = 'Smiles'\n",
    "colNames_activity = 'F%_Rat,EstFa_Rat,permeability,efflux,hERG_IC50,hERG_mixedIC50,logD_CDD,fakeCol'"
=======
    "fileName_out = defineOutputFolder(fileName_out)\n",
    "\n",
    "colName_mid = 'Compound Name'\n",
    "colName_smi = 'Smiles'\n",
    "colNames_activity = 'permeability,fakeCol'"
>>>>>>> 4e14183d906f40846fab9a0c104609029a22b9e6
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Loading csv from ./Data_ADMET_4_MMP_2024Aug27.csv\n",
      "\tThe original csv file has 25714 rows and 49 columns\n",
      "\tColumn for compound ID is Compound Name\n",
      "\tColumn for compound SMILES is Smiles\n",
<<<<<<< HEAD
      "\tColumns for compound activity includes ['F%_Rat', 'EstFa_Rat', 'permeability', 'efflux', 'hERG_IC50', 'hERG_mixedIC50', 'logD_CDD', 'fakeCol']\n",
      "\t---->Warning! fakeCol is not in the csv file, pls check ...\n",
      "\tThere are total 25714 molecules in the csv with Structure(SMILES)\n",
      "2. Prepare the smi & prop file for MMPs-DB analysis\n",
      "\tThe SMILES strings have been saved into .smi file: /mnt/data0/Research/5_Automation/mmp/rdkit/Application_MMPsAnalysis/MMPs_results/Compounds_All.smi\n",
      "\tThe property data have been saved into .csv file: /mnt/data0/Research/5_Automation/mmp/rdkit/Application_MMPsAnalysis/MMPs_results/Compounds_All.smi\n",
      "3. Fragment the SMILES\n"
=======
      "\tColumns for compound activity includes ['permeability', 'fakeCol']\n",
      "\t---->Warning! fakeCol is not in the csv file, pls check ...\n",
      "\tThere are total 25714 molecules in the csv with Structure(SMILES)\n",
      "2. Fragment the SMILES\n",
      "\tThe SMILES strings have been saved into .smi file: /mnt/data0/Research/5_Automation/mmp/rdkit/Application_MMPsAnalysis/MMPs_results/Compounds_All.smi\n",
      "\tThe property data have been saved into .csv file: /mnt/data0/Research/5_Automation/mmp/rdkit/Application_MMPsAnalysis/MMPs_results/Compounds_All.smi\n"
>>>>>>> 4e14183d906f40846fab9a0c104609029a22b9e6
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "Preparing record 23905[12:36:22] Can't kekulize mol.  Unkekulized atoms: 6\n",
=======
      "Preparing record 23916[18:09:31] Can't kekulize mol.  Unkekulized atoms: 6\n",
>>>>>>> 4e14183d906f40846fab9a0c104609029a22b9e6
      "                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tThe fragmentation is completed and saved into file /mnt/data0/Research/5_Automation/mmp/rdkit/Application_MMPsAnalysis/MMPs_results/Compounds_All.fragdb\n",
<<<<<<< HEAD
      "4.1 Indexing to find the matched molecular pairs in the fragment file\n",
      "4.2 Now load the activity/property data\n"
=======
      "3. Indexing to find the matched molecular pairs in the fragment file\n",
      "4. Now load the activity/property data\n"
>>>>>>> 4e14183d906f40846fab9a0c104609029a22b9e6
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "                                                                            \r"
=======
      "                                                                         \r"
>>>>>>> 4e14183d906f40846fab9a0c104609029a22b9e6
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "\tThe indexing/mmp generation is completed and saved into file /mnt/data0/Research/5_Automation/mmp/rdkit/Application_MMPsAnalysis/MMPs_results/Compounds_All.mmpdb\n",
      "\t<pair> table has been saved into /mnt/data0/Research/5_Automation/mmp/rdkit/Application_MMPsAnalysis/MMPs_results/DB_tables/DB_table_pair.csv\n",
      "\t<compound> table has been saved into /mnt/data0/Research/5_Automation/mmp/rdkit/Application_MMPsAnalysis/MMPs_results/DB_tables/DB_table_compound.csv\n",
      "\t<compound_property> table has been saved into /mnt/data0/Research/5_Automation/mmp/rdkit/Application_MMPsAnalysis/MMPs_results/DB_tables/DB_table_compound_property.csv\n",
      "\t<property_name> table has been saved into /mnt/data0/Research/5_Automation/mmp/rdkit/Application_MMPsAnalysis/MMPs_results/DB_tables/DB_table_property_name.csv\n",
      "\t<constant_smiles> table has been saved into /mnt/data0/Research/5_Automation/mmp/rdkit/Application_MMPsAnalysis/MMPs_results/DB_tables/DB_table_constant_smiles.csv\n",
      "\t<rule> table has been saved into /mnt/data0/Research/5_Automation/mmp/rdkit/Application_MMPsAnalysis/MMPs_results/DB_tables/DB_table_rule.csv\n",
      "\t<rule_smiles> table has been saved into /mnt/data0/Research/5_Automation/mmp/rdkit/Application_MMPsAnalysis/MMPs_results/DB_tables/DB_table_rule_smiles.csv\n",
      "\t<rule_environment> table has been saved into /mnt/data0/Research/5_Automation/mmp/rdkit/Application_MMPsAnalysis/MMPs_results/DB_tables/DB_table_rule_environment.csv\n",
      "\t<rule_environment_statistics> table has been saved into /mnt/data0/Research/5_Automation/mmp/rdkit/Application_MMPsAnalysis/MMPs_results/DB_tables/DB_table_rule_environment_statistics.csv\n",
      "\t<environment_fingerprint> table has been saved into /mnt/data0/Research/5_Automation/mmp/rdkit/Application_MMPsAnalysis/MMPs_results/DB_tables/DB_table_environment_fingerprint.csv\n"
=======
      "\tThe indexing/mmp generation is completed and saved into file /mnt/data0/Research/5_Automation/mmp/rdkit/Application_MMPsAnalysis/MMPs_results/Compounds_All.mmpdb\n"
>>>>>>> 4e14183d906f40846fab9a0c104609029a22b9e6
     ]
    }
   ],
   "source": [
<<<<<<< HEAD
    "## 1. Load the raw data from csv file\n",
    "dataTable_raw, colName_prop_list = CSV_loader(fileName_in, colName_mid, colName_smi, colNames_activity, sep=',')\n",
    "\n",
    "## 2. Prepare the SMILES file and property CSV file\n",
    "file_smi, file_prop_csv = Smiles_Prep(dataTable_raw, colName_mid, colName_smi, colName_prop_list, fileName_out)\n",
    "\n",
    "## 3. Fragment the SMILES\n",
    "file_fragdb = Smiles_fragmentation(fileName_out, file_smi)\n",
    "\n",
    "## 4. Indexing to find the MMPs in the fragment file & Load the activity/property data\n",
    "file_mmpdb = Index_LinkActivity(fileName_out, file_fragdb, file_prop_csv)\n",
    "\n",
    "## 5. Extracing all tables from database file\n",
    "dataDict_tables = DataExtractionFromDB(file_mmpdb, fileName_out)\n",
    "\n",
    "## 6. Clean up the MMPs data from the DB\n",
    "dataDict = MMPs_DataClean(dataDict_tables, add_symetric=True)"
=======
    "dataTable_raw, colName_prop_list = CSV_loader(fileName_in, colName_mid, colName_smi, colNames_activity, sep=',')\n",
    "## 1. Prepare the SMILES file and property CSV file\n",
    "file_smi, file_prop_csv = Smiles_Prep(dataTable_raw, colName_mid, colName_smi, colName_prop_list, fileName_out)\n",
    "## 2. Fragment the SMILES\n",
    "file_fragdb = Smiles_fragmentation(fileName_out, file_smi)\n",
    "## 3. Indexing to find the MMPs in the fragment file & Load the activity/property data\n",
    "file_mmpdb = Index_LinkActivity(fileName_out, file_fragdb, file_prop_csv)"
>>>>>>> 4e14183d906f40846fab9a0c104609029a22b9e6
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(268948, 24)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pair_info</th>\n",
       "      <th>pair_id</th>\n",
       "      <th>compound1_id</th>\n",
       "      <th>compound2_id</th>\n",
       "      <th>pair_detail</th>\n",
       "      <th>KT_id_1</th>\n",
       "      <th>KT_id_2</th>\n",
       "      <th>Smiles_1</th>\n",
       "      <th>Smiles_2</th>\n",
       "      <th>F%_Rat_1</th>\n",
       "      <th>...</th>\n",
       "      <th>permeability_2</th>\n",
       "      <th>efflux_1</th>\n",
       "      <th>efflux_2</th>\n",
       "      <th>hERG_IC50_1</th>\n",
       "      <th>hERG_IC50_2</th>\n",
       "      <th>hERG_mixedIC50_1</th>\n",
       "      <th>hERG_mixedIC50_2</th>\n",
       "      <th>logD_CDD_1</th>\n",
       "      <th>logD_CDD_2</th>\n",
       "      <th>Num_Consts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1==&gt;2</td>\n",
       "      <td>(1,2)</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>{1: [1, 2, 3, 4, 5, 6], 17071: [1048406, 10484...</td>\n",
       "      <td>KT-0013567</td>\n",
       "      <td>KT-0013672</td>\n",
       "      <td>C1=C(C2=CC=CC=C2)N(C2=CC=C(NC(C)=O)C=C2)C(=O)/...</td>\n",
       "      <td>C1=C(C2=CC=CC=C2)N(C2=CC=C(NC(C)=O)C=C2)C(=O)/...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.74391</td>\n",
       "      <td>4.26768</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2==&gt;1</td>\n",
       "      <td>(1,2)</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>{1: [], 17071: []}</td>\n",
       "      <td>KT-0013672</td>\n",
       "      <td>KT-0013567</td>\n",
       "      <td>C1=C(C2=CC=CC=C2)N(C2=CC=C(NC(C)=O)C=C2)C(=O)/...</td>\n",
       "      <td>C1=C(C2=CC=CC=C2)N(C2=CC=C(NC(C)=O)C=C2)C(=O)/...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.26768</td>\n",
       "      <td>4.74391</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10==&gt;1592</td>\n",
       "      <td>(10,1592)</td>\n",
       "      <td>10</td>\n",
       "      <td>1592</td>\n",
       "      <td>{942: [62186, 62187, 62188, 62189, 62190, 62191]}</td>\n",
       "      <td>KT-0035007</td>\n",
       "      <td>KT-0035717</td>\n",
       "      <td>C1=CC(Br)=CC=C1[C@@H]1C[C@H]1C(=O)N1CC(C2=CC=C...</td>\n",
       "      <td>O=C(C1=CNN=C1I)N1CC(C2=CC=C3C(=C2)NC(C(=O)N(C)...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.60718</td>\n",
       "      <td>2.16124</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   pair_info    pair_id compound1_id compound2_id  \\\n",
       "0      1==>2      (1,2)            1            2   \n",
       "1      2==>1      (1,2)            2            1   \n",
       "2  10==>1592  (10,1592)           10         1592   \n",
       "\n",
       "                                         pair_detail     KT_id_1     KT_id_2  \\\n",
       "0  {1: [1, 2, 3, 4, 5, 6], 17071: [1048406, 10484...  KT-0013567  KT-0013672   \n",
       "1                                 {1: [], 17071: []}  KT-0013672  KT-0013567   \n",
       "2  {942: [62186, 62187, 62188, 62189, 62190, 62191]}  KT-0035007  KT-0035717   \n",
       "\n",
       "                                            Smiles_1  \\\n",
       "0  C1=C(C2=CC=CC=C2)N(C2=CC=C(NC(C)=O)C=C2)C(=O)/...   \n",
       "1  C1=C(C2=CC=CC=C2)N(C2=CC=C(NC(C)=O)C=C2)C(=O)/...   \n",
       "2  C1=CC(Br)=CC=C1[C@@H]1C[C@H]1C(=O)N1CC(C2=CC=C...   \n",
       "\n",
       "                                            Smiles_2 F%_Rat_1  ...  \\\n",
       "0  C1=C(C2=CC=CC=C2)N(C2=CC=C(NC(C)=O)C=C2)C(=O)/...      NaN  ...   \n",
       "1  C1=C(C2=CC=CC=C2)N(C2=CC=C(NC(C)=O)C=C2)C(=O)/...      NaN  ...   \n",
       "2  O=C(C1=CNN=C1I)N1CC(C2=CC=C3C(=C2)NC(C(=O)N(C)...      NaN  ...   \n",
       "\n",
       "  permeability_2 efflux_1 efflux_2 hERG_IC50_1 hERG_IC50_2 hERG_mixedIC50_1  \\\n",
       "0            NaN      NaN      NaN         NaN         NaN              NaN   \n",
       "1            NaN      NaN      NaN         NaN         NaN              NaN   \n",
       "2            NaN      NaN      NaN         NaN         NaN              NaN   \n",
       "\n",
       "  hERG_mixedIC50_2 logD_CDD_1 logD_CDD_2 Num_Consts  \n",
       "0              NaN    4.74391    4.26768          2  \n",
       "1              NaN    4.26768    4.74391          2  \n",
       "2              NaN    4.60718    2.16124          1  \n",
       "\n",
       "[3 rows x 24 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##\n",
    "dataTable = pd.DataFrame.from_dict(dataDict).T\n",
    "dataTable['Num_Consts'] = dataTable['pair_detail'].apply(lambda x: len(x))\n",
    "dataTable = dataTable.sort_values(by=[\"pair_id\", \"pair_info\"], ascending=[True, True]).reset_index(drop=True)\n",
    "print(dataTable.shape)\n",
    "dataTable.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>KT_id_1</th>\n",
       "      <th>Smiles_1</th>\n",
       "      <th>KT_id_2</th>\n",
       "      <th>Smiles_2</th>\n",
       "      <th>F%_Rat_1</th>\n",
       "      <th>EstFa_Rat_1</th>\n",
       "      <th>permeability_1</th>\n",
       "      <th>efflux_1</th>\n",
       "      <th>hERG_IC50_1</th>\n",
       "      <th>hERG_mixedIC50_1</th>\n",
       "      <th>...</th>\n",
       "      <th>EstFa_Rat_2</th>\n",
       "      <th>permeability_2</th>\n",
       "      <th>efflux_2</th>\n",
       "      <th>hERG_IC50_2</th>\n",
       "      <th>hERG_mixedIC50_2</th>\n",
       "      <th>logD_CDD_2</th>\n",
       "      <th>pair_info</th>\n",
       "      <th>pair_id</th>\n",
       "      <th>Num_Consts</th>\n",
       "      <th>pair_detail</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KT-0013567</td>\n",
       "      <td>C1=C(C2=CC=CC=C2)N(C2=CC=C(NC(C)=O)C=C2)C(=O)/...</td>\n",
       "      <td>KT-0013672</td>\n",
       "      <td>C1=C(C2=CC=CC=C2)N(C2=CC=C(NC(C)=O)C=C2)C(=O)/...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.26768</td>\n",
       "      <td>1==&gt;2</td>\n",
       "      <td>(1,2)</td>\n",
       "      <td>2</td>\n",
       "      <td>{1: [1, 2, 3, 4, 5, 6], 17071: [1048406, 10484...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KT-0013672</td>\n",
       "      <td>C1=C(C2=CC=CC=C2)N(C2=CC=C(NC(C)=O)C=C2)C(=O)/...</td>\n",
       "      <td>KT-0013567</td>\n",
       "      <td>C1=C(C2=CC=CC=C2)N(C2=CC=C(NC(C)=O)C=C2)C(=O)/...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.74391</td>\n",
       "      <td>2==&gt;1</td>\n",
       "      <td>(1,2)</td>\n",
       "      <td>2</td>\n",
       "      <td>{1: [], 17071: []}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KT-0035007</td>\n",
       "      <td>C1=CC(Br)=CC=C1[C@@H]1C[C@H]1C(=O)N1CC(C2=CC=C...</td>\n",
       "      <td>KT-0035717</td>\n",
       "      <td>O=C(C1=CNN=C1I)N1CC(C2=CC=C3C(=C2)NC(C(=O)N(C)...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.16124</td>\n",
       "      <td>10==&gt;1592</td>\n",
       "      <td>(10,1592)</td>\n",
       "      <td>1</td>\n",
       "      <td>{942: [62186, 62187, 62188, 62189, 62190, 62191]}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      KT_id_1                                           Smiles_1     KT_id_2  \\\n",
       "0  KT-0013567  C1=C(C2=CC=CC=C2)N(C2=CC=C(NC(C)=O)C=C2)C(=O)/...  KT-0013672   \n",
       "1  KT-0013672  C1=C(C2=CC=CC=C2)N(C2=CC=C(NC(C)=O)C=C2)C(=O)/...  KT-0013567   \n",
       "2  KT-0035007  C1=CC(Br)=CC=C1[C@@H]1C[C@H]1C(=O)N1CC(C2=CC=C...  KT-0035717   \n",
       "\n",
       "                                            Smiles_2 F%_Rat_1 EstFa_Rat_1  \\\n",
       "0  C1=C(C2=CC=CC=C2)N(C2=CC=C(NC(C)=O)C=C2)C(=O)/...      NaN         NaN   \n",
       "1  C1=C(C2=CC=CC=C2)N(C2=CC=C(NC(C)=O)C=C2)C(=O)/...      NaN         NaN   \n",
       "2  O=C(C1=CNN=C1I)N1CC(C2=CC=C3C(=C2)NC(C(=O)N(C)...      NaN         NaN   \n",
       "\n",
       "  permeability_1 efflux_1 hERG_IC50_1 hERG_mixedIC50_1  ... EstFa_Rat_2  \\\n",
       "0            NaN      NaN         NaN              NaN  ...         NaN   \n",
       "1            NaN      NaN         NaN              NaN  ...         NaN   \n",
       "2            NaN      NaN         NaN              NaN  ...         NaN   \n",
       "\n",
       "  permeability_2 efflux_2 hERG_IC50_2 hERG_mixedIC50_2 logD_CDD_2  pair_info  \\\n",
       "0            NaN      NaN         NaN              NaN    4.26768      1==>2   \n",
       "1            NaN      NaN         NaN              NaN    4.74391      2==>1   \n",
       "2            NaN      NaN         NaN              NaN    2.16124  10==>1592   \n",
       "\n",
       "     pair_id Num_Consts                                        pair_detail  \n",
       "0      (1,2)          2  {1: [1, 2, 3, 4, 5, 6], 17071: [1048406, 10484...  \n",
       "1      (1,2)          2                                 {1: [], 17071: []}  \n",
       "2  (10,1592)          1  {942: [62186, 62187, 62188, 62189, 62190, 62191]}  \n",
       "\n",
       "[3 rows x 22 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_basic = ['KT_id_1', 'Smiles_1', 'KT_id_2', 'Smiles_2']\n",
    "col_bioassay = [f\"{x}_1\" for x in colName_prop_list] + [f\"{x}_2\" for x in colName_prop_list]\n",
    "col_pairinfo = ['pair_info', 'pair_id', 'Num_Consts', 'pair_detail']\n",
    "dataTable = dataTable[col_basic + col_bioassay + col_pairinfo]\n",
    "dataTable.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
=======
>>>>>>> 4e14183d906f40846fab9a0c104609029a22b9e6
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
<<<<<<< HEAD
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
=======
   "source": [
    "!mmpdb list ./results/Compounds_All.mmpdb"
   ]
>>>>>>> 4e14183d906f40846fab9a0c104609029a22b9e6
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !mmpdb --help\n",
    "# !mmpdb help-admin\n",
    "# !mmpdb index --help\n",
    "\n",
    "# !mmpdb rulecat --help\n",
    "# !mmpdb rulecat ./results/hERG_All_1956_2024Jun14.mmpdb -o ./results/catfolder/hERG_All_1956_2024Jun14_rulecat.csv\n",
    "\n",
    "# !mmpdb ruleenvcat --help\n",
    "# !mmpdb ruleenvcat ./results/hERG_All_1956_2024Jun14.mmpdb -o ./results/catfolder/hERG_All_1956_2024Jun14_ruleenvcat.csv\n",
    "\n",
    "# !mmpdb propcat --help\n",
    "# !mmpdb propcat ./results/hERG_All_1956_2024Jun14.mmpdb -o ./results/catfolder/hERG_All_1956_2024Jun14_propcat.csv\n",
    "\n",
    "# !mmpdb proprulecat --help\n",
    "# !mmpdb proprulecat ./results/hERG_All_1956_2024Jun14.mmpdb -o ./results/catfolder/hERG_All_1956_2024Jun14_proprulecat.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
