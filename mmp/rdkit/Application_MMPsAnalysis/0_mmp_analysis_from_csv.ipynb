{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import chardet\n",
    "import subprocess\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################################################\n",
    "##################################### Custom Tools ###########################################\n",
    "##############################################################################################\n",
    "def determine_encoding(dataFile):\n",
    "    # Step 1: Open the CSV file in binary mode\n",
    "    with open(dataFile, 'rb') as f:\n",
    "        data = f.read()\n",
    "    # Step 2: Detect the encoding using the chardet library\n",
    "    encoding_result = chardet.detect(data)\n",
    "    # Step 3: Retrieve the encoding information\n",
    "    encoding = encoding_result['encoding']\n",
    "    # Step 4: Print/export the detected encoding information\n",
    "    # print(\"Detected Encoding:\", encoding)\n",
    "    return encoding\n",
    "\n",
    "def defineOutputFolder(fileName_out):\n",
    "    if fileName_out is None:\n",
    "        fileName_out = os.path.join(os.getcwd(), 'MMPs_results')\n",
    "    \n",
    "    os.makedirs(fileName_out) if not os.path.exists(fileName_out) else print(f'\\t---->{fileName_out} is existing')\n",
    "    return fileName_out\n",
    "\n",
    "##############################################################################################\n",
    "########################### Load original csv for MMPs analysis ##############################\n",
    "##############################################################################################\n",
    "def CSV_loader(fileName_in, colName_mid, colName_smi, colNames_activity, sep=','):\n",
    "    print(f\"1. Loading csv from {fileName_in}\")\n",
    "    assert os.path.exists(fileName_in), f\"File {fileName_in} does not exist\"\n",
    "    ##\n",
    "    encoding = determine_encoding(fileName_in)\n",
    "    ##\n",
    "    dataTable_raw = pd.read_csv(fileName_in, sep=sep, encoding=encoding)\n",
    "    print(f\"\\tThe original csv file has {dataTable_raw.shape[0]} rows and {dataTable_raw.shape[1]} columns\")\n",
    "    print(f\"\\tColumn for compound ID is {colName_mid}\")\n",
    "    print(f\"\\tColumn for compound SMILES is {colName_smi}\")\n",
    "\n",
    "    colName_prop_list = colNames_activity.split(',')\n",
    "    print(f\"\\tColumns for compound activity includes {colName_prop_list}\")\n",
    "    for prop_name in colName_prop_list:\n",
    "        if prop_name not in dataTable_raw.columns:\n",
    "            print(f\"\\t---->Warning! {prop_name} is not in the csv file, pls check ...\")\n",
    "            colName_prop_list.remove(prop_name)\n",
    "    ##\n",
    "    dataTable_raw = dataTable_raw.dropna(subset=[colName_mid, colName_smi]).reset_index(drop=True)\n",
    "    print(f\"\\tThere are total {dataTable_raw.shape[0]} molecules in the csv with Structure(SMILES)\")\n",
    "\n",
    "    return dataTable_raw, colName_prop_list\n",
    "\n",
    "##############################################################################################\n",
    "######################## Prepare .smi and csv for MMPs analysis ##############################\n",
    "##############################################################################################\n",
    "def Smiles_Prep(dataTable_raw, colName_mid, colName_smi, colName_prop_list, fileName_out):\n",
    "    print(f\"2. Fragment the SMILES\")\n",
    "    ## the SMILES file for fragmentation\n",
    "    file_smi = f'{fileName_out}/Compounds_All.smi'\n",
    "    file_prop_csv = f'{fileName_out}/Property_All.csv'\n",
    "    delimiter = ' '\n",
    "\n",
    "    data_dict_prop = {}\n",
    "    with open(file_smi, \"w\") as output_file:\n",
    "        # output_file.write(f'SMILES{delimiter}ID' + \"\\n\")\n",
    "        for idx in dataTable_raw.index:\n",
    "            mol_id = dataTable_raw[colName_mid][idx]\n",
    "            mol_smi = dataTable_raw[colName_smi][idx]\n",
    "\n",
    "            ## prepare the SMILES output\n",
    "            this_line = f'{mol_smi}{delimiter}{mol_id}'\n",
    "            output_file.write(this_line + \"\\n\")  # Add a newline character after each string\n",
    "\n",
    "            ## prepare the property CSV output\n",
    "            data_dict_prop[idx] = {}\n",
    "            data_dict_prop[idx]['ID'] = mol_id\n",
    "\n",
    "            for prop_name in colName_prop_list:\n",
    "                try:\n",
    "                    if dataTable_raw[prop_name].notna()[idx]:\n",
    "                        mol_prop = float(dataTable_raw[prop_name][idx])\n",
    "                    else:\n",
    "                        mol_prop = \"*\"\n",
    "                except Exception as e:\n",
    "                    data_dict_prop[idx][prop_name] = \"*\"\n",
    "                    print(f'\\t---->Warning! This mol {mol_id} does not have a proper property value: {e}')\n",
    "                else:\n",
    "                    data_dict_prop[idx][prop_name] = mol_prop\n",
    "        print(f'\\tThe SMILES strings have been saved into .smi file: {file_smi}')\n",
    "        \n",
    "    ## save the csv results\n",
    "    data_table_prop = pd.DataFrame.from_dict(data_dict_prop).T\n",
    "    data_table_prop.to_csv(file_prop_csv, index=False, sep=delimiter)\n",
    "    print(f'\\tThe property data have been saved into .csv file: {file_smi}')\n",
    "    return file_smi, file_prop_csv\n",
    "\n",
    "##############################################################################################\n",
    "##################################### Fragment the SMILES ####################################\n",
    "##############################################################################################\n",
    "def Smiles_fragmentation(fileName_out, file_smi):\n",
    "    \n",
    "    file_fragdb = f'{fileName_out}/Compounds_All.fragdb'\n",
    "    commandLine = ['mmpdb', 'fragment', file_smi, '-o', file_fragdb]\n",
    "    process = subprocess.Popen(commandLine, stdout=subprocess.PIPE)\n",
    "    output, error = process.communicate()\n",
    "    print(f'\\tThe fragmentation is completed and saved into file {file_fragdb}')\n",
    "    return file_fragdb\n",
    "\n",
    "##############################################################################################\n",
    "################## Indexing to find the MMPs and load the activity data ######################\n",
    "##############################################################################################\n",
    "def Index_LinkActivity(fileName_out, file_fragdb, file_prop_csv):\n",
    "    print(f\"3. Indexing to find the matched molecular pairs in the fragment file\")\n",
    "    print(f\"4. Now load the activity/property data\")\n",
    "    file_mmpdb = f'{fileName_out}/Compounds_All.mmpdb'\n",
    "    commandLine = ['mmpdb', 'index', file_fragdb, '-o', file_mmpdb, '--properties', file_prop_csv]\n",
    "    process = subprocess.Popen(commandLine, stdout=subprocess.PIPE)\n",
    "    output, error = process.communicate()\n",
    "    print(f'\\tThe indexing/mmp generation is completed and saved into file {file_mmpdb}')\n",
    "    return file_mmpdb\n",
    "\n",
    "##############################################################################################\n",
    "############################### Loading data from database ###################################\n",
    "##############################################################################################\n",
    "def call_my_query(db_file, my_query):\n",
    "    ## connect to the SQLIte database\n",
    "    my_connection = sqlite3.connect(db_file)\n",
    "\n",
    "    ## create a cursor object\n",
    "    my_cursor = my_connection.cursor()\n",
    "\n",
    "    ## excute the query\n",
    "    my_cursor.execute(my_query)\n",
    "\n",
    "    ## fetch all the rows\n",
    "    rows = my_cursor.fetchall()\n",
    "    \n",
    "    ## export the results\n",
    "    data_list = [row for row in rows]\n",
    "\n",
    "    my_connection.close()\n",
    "    return data_list\n",
    "\n",
    "def extract_tables(db_file, table_name):\n",
    "    ## extract table data from SQLite DB\n",
    "    my_query_colName = f\"PRAGMA table_info({table_name})\"\n",
    "    colName_list = call_my_query(db_file, my_query_colName)\n",
    "\n",
    "    my_query_data = f\"SELECT * FROM {table_name}\"\n",
    "    data_list = call_my_query(db_file, my_query_data)\n",
    "\n",
    "    ## clean up data\n",
    "    dataDict = {}\n",
    "    for row_tuple in data_list:\n",
    "        idx = row_tuple[0]\n",
    "        dataDict[idx] = {}\n",
    "\n",
    "        for col in colName_list:\n",
    "            colIdx, colName = col[0], col[1]\n",
    "            dataDict[idx][colName] = row_tuple[colIdx]\n",
    "    return dataDict\n",
    "    \n",
    "##############################################################################################\n",
    "############################### Loading data from database ###################################\n",
    "##############################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t---->/mnt/data0/Research/5_Automation/mmp/rdkit/Application_MMPsAnalysis/MMPs_results is existing\n"
     ]
    }
   ],
   "source": [
    "##############################################################################################\n",
    "########################### argument  original csv for MMPs analysis ##############################\n",
    "##############################################################################################\n",
    "\n",
    "fileName_in = f'./Data_ADMET_4_MMP_2024Aug27.csv'    ## input CSV\n",
    "sep = ','\n",
    "\n",
    "fileName_out = None    # output folder\n",
    "fileName_out = defineOutputFolder(fileName_out)\n",
    "\n",
    "colName_mid = 'Compound Name'\n",
    "colName_smi = 'Smiles'\n",
    "colNames_activity = 'permeability,fakeCol'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Loading csv from ./Data_ADMET_4_MMP_2024Aug27.csv\n",
      "\tThe original csv file has 25714 rows and 49 columns\n",
      "\tColumn for compound ID is Compound Name\n",
      "\tColumn for compound SMILES is Smiles\n",
      "\tColumns for compound activity includes ['permeability', 'fakeCol']\n",
      "\t---->Warning! fakeCol is not in the csv file, pls check ...\n",
      "\tThere are total 25714 molecules in the csv with Structure(SMILES)\n",
      "2. Fragment the SMILES\n",
      "\tThe SMILES strings have been saved into .smi file: /mnt/data0/Research/5_Automation/mmp/rdkit/Application_MMPsAnalysis/MMPs_results/Compounds_All.smi\n",
      "\tThe property data have been saved into .csv file: /mnt/data0/Research/5_Automation/mmp/rdkit/Application_MMPsAnalysis/MMPs_results/Compounds_All.smi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preparing record 23916[18:09:31] Can't kekulize mol.  Unkekulized atoms: 6\n",
      "                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tThe fragmentation is completed and saved into file /mnt/data0/Research/5_Automation/mmp/rdkit/Application_MMPsAnalysis/MMPs_results/Compounds_All.fragdb\n",
      "3. Indexing to find the matched molecular pairs in the fragment file\n",
      "4. Now load the activity/property data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tThe indexing/mmp generation is completed and saved into file /mnt/data0/Research/5_Automation/mmp/rdkit/Application_MMPsAnalysis/MMPs_results/Compounds_All.mmpdb\n"
     ]
    }
   ],
   "source": [
    "dataTable_raw, colName_prop_list = CSV_loader(fileName_in, colName_mid, colName_smi, colNames_activity, sep=',')\n",
    "## 1. Prepare the SMILES file and property CSV file\n",
    "file_smi, file_prop_csv = Smiles_Prep(dataTable_raw, colName_mid, colName_smi, colName_prop_list, fileName_out)\n",
    "## 2. Fragment the SMILES\n",
    "file_fragdb = Smiles_fragmentation(fileName_out, file_smi)\n",
    "## 3. Indexing to find the MMPs in the fragment file & Load the activity/property data\n",
    "file_mmpdb = Index_LinkActivity(fileName_out, file_fragdb, file_prop_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mmpdb list ./results/Compounds_All.mmpdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !mmpdb --help\n",
    "# !mmpdb help-admin\n",
    "# !mmpdb index --help\n",
    "\n",
    "# !mmpdb rulecat --help\n",
    "# !mmpdb rulecat ./results/hERG_All_1956_2024Jun14.mmpdb -o ./results/catfolder/hERG_All_1956_2024Jun14_rulecat.csv\n",
    "\n",
    "# !mmpdb ruleenvcat --help\n",
    "# !mmpdb ruleenvcat ./results/hERG_All_1956_2024Jun14.mmpdb -o ./results/catfolder/hERG_All_1956_2024Jun14_ruleenvcat.csv\n",
    "\n",
    "# !mmpdb propcat --help\n",
    "# !mmpdb propcat ./results/hERG_All_1956_2024Jun14.mmpdb -o ./results/catfolder/hERG_All_1956_2024Jun14_propcat.csv\n",
    "\n",
    "# !mmpdb proprulecat --help\n",
    "# !mmpdb proprulecat ./results/hERG_All_1956_2024Jun14.mmpdb -o ./results/catfolder/hERG_All_1956_2024Jun14_proprulecat.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
