{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from rdkit import Chem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileName_out = \"./MMPs_results\"\n",
    "DB_dict = f\"{fileName_out}/DB_tables/DB_table_all.dict\"\n",
    "\n",
    "with open(DB_dict, \"rb\") as ifh:\n",
    "    dataDict_tables = pickle.load(ifh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findPropValue(dbTable_propValue, cid, prop_id, average=False):\n",
    "    cond_1 = (dbTable_propValue[\"compound_id\"]==cid)\n",
    "    cond_2 = (dbTable_propValue[\"property_name_id\"]==prop_id)\n",
    "    \n",
    "    match_data = dbTable_propValue[cond_1 & cond_2][\"value\"].values\n",
    "\n",
    "    if match_data.shape[0] <= 0:\n",
    "        result = np.nan\n",
    "    else:\n",
    "        if average:\n",
    "            if match_data.shape[0] > 1:\n",
    "                print(f\"\\t\\tWarning! Compound {cid} has multiple <{prop_id}> values\")\n",
    "                result = np.meam(match_data)\n",
    "            else:\n",
    "                result = match_data[0]\n",
    "        else:\n",
    "            result = np.array2string(match_data, separator=',')\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current num_pairs: 146198\n"
     ]
    }
   ],
   "source": [
    "dataTable_pair = dataDict_tables[\"pair\"]\n",
    "dbTable_cmpd = dataDict_tables[\"compound\"]\n",
    "dbTable_propName = dataDict_tables[\"property_name\"]\n",
    "dbTable_propValue = dataDict_tables[\"compound_property\"]\n",
    "\n",
    "dataDict = {}\n",
    "for idx in dataTable_pair.index:\n",
    "    pair_idx = dataTable_pair['id'][idx]\n",
    "    cid_1 = dataTable_pair['compound1_id'][idx]\n",
    "    cid_2 = dataTable_pair['compound2_id'][idx]\n",
    "    const_id = dataTable_pair['constant_id'][idx]\n",
    "    rule_env_id = dataTable_pair['rule_environment_id'][idx]\n",
    "\n",
    "    ## initialize the sub-dict\n",
    "    pair_info = f\"{cid_1}==>{cid_2}\"\n",
    "    if pair_info not in dataDict:\n",
    "        ## add pair basic info\n",
    "        dataDict[pair_info] = {}\n",
    "        dataDict[pair_info][\"pair_info\"] = pair_info\n",
    "        dataDict[pair_info][\"pair_id\"] = f\"({min([cid_1, cid_2])},{max([cid_1, cid_2])})\"\n",
    "        dataDict[pair_info][\"compound1_id\"] = cid_1\n",
    "        dataDict[pair_info][\"compound2_id\"] = cid_2\n",
    "        dataDict[pair_info][\"pair_detail\"] = {}\n",
    "\n",
    "        ## add compound info\n",
    "        dataDict[pair_info][\"KT_id_1\"] = dbTable_cmpd['public_id'][cid_1]\n",
    "        dataDict[pair_info][\"KT_id_2\"] = dbTable_cmpd['public_id'][cid_2]\n",
    "        dataDict[pair_info][\"Smiles_1\"] = dbTable_cmpd['input_smiles'][cid_1]\n",
    "        dataDict[pair_info][\"Smiles_2\"] = dbTable_cmpd['input_smiles'][cid_2]\n",
    "\n",
    "        ## add compound prop info\n",
    "        for prop_id in dbTable_propName.index:\n",
    "            prop_name = dbTable_propName['name'][prop_id]\n",
    "\n",
    "            dataDict[pair_info][f\"{prop_name}_1\"] = findPropValue(dbTable_propValue, cid_1, prop_id, average=True)\n",
    "            dataDict[pair_info][f\"{prop_name}_2\"] = findPropValue(dbTable_propValue, cid_2, prop_id, average=True)\n",
    "\n",
    "    ## add pair details information (constant part)\n",
    "    if const_id not in dataDict[pair_info][\"pair_detail\"]:\n",
    "        dataDict[pair_info][\"pair_detail\"][const_id] = []\n",
    "    \n",
    "    ## add pair details information (rule_env)\n",
    "    if rule_env_id not in dataDict[pair_info][\"pair_detail\"][const_id]:\n",
    "        dataDict[pair_info][\"pair_detail\"][const_id].append(rule_env_id)\n",
    "\n",
    "print(f\"Current num_pairs: {len(dataDict)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modified num_pairs: 268948\n",
      "146198 0\n"
     ]
    }
   ],
   "source": [
    "#####################################################################\n",
    "list_pair_info_4loop = copy.deepcopy(list(dataDict.keys()))\n",
    "list_pair_info_4check = copy.deepcopy(list(dataDict.keys()))\n",
    "for pair_info in list_pair_info_4loop:\n",
    "    if pair_info in list_pair_info_4check:\n",
    "        list_pair_info_4check.remove(pair_info)\n",
    "\n",
    "        ## reverse pair\n",
    "        cid_1, cid_2 = pair_info.split(\"==>\")\n",
    "        pair_info_revs = f\"{cid_2}==>{cid_1}\"\n",
    "        if pair_info_revs in list_pair_info_4check:\n",
    "            list_pair_info_4check.remove(pair_info_revs)\n",
    "        else:\n",
    "            ## if reversed pair not in check list, add it in the dict\n",
    "            dataDict[pair_info_revs] = {}\n",
    "            dataDict[pair_info_revs][\"pair_info\"] = pair_info_revs\n",
    "            dataDict[pair_info_revs][\"pair_id\"] = dataDict[pair_info][\"pair_id\"]\n",
    "            dataDict[pair_info_revs][\"pair_detail\"] = {key: [] for key in dataDict[pair_info][\"pair_detail\"]}\n",
    "\n",
    "            for tmp_key in dataDict[pair_info]:\n",
    "                if '1' in tmp_key:\n",
    "                    dataDict[pair_info_revs][tmp_key] = dataDict[pair_info][tmp_key.replace('1', '2')]\n",
    "                elif '2' in tmp_key:\n",
    "                    dataDict[pair_info_revs][tmp_key] = dataDict[pair_info][tmp_key.replace('2', '1')]\n",
    "                else:\n",
    "                    pass\n",
    "    else:\n",
    "        ## this pair was removed from check list because it's the revs pair of another pair\n",
    "        pass\n",
    "\n",
    "print(f\"Modified num_pairs: {len(dataDict)}\")\n",
    "print(len(list_pair_info_4loop), len(list_pair_info_4check))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(268948, 24)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pair_info</th>\n",
       "      <th>pair_id</th>\n",
       "      <th>compound1_id</th>\n",
       "      <th>compound2_id</th>\n",
       "      <th>pair_detail</th>\n",
       "      <th>KT_id_1</th>\n",
       "      <th>KT_id_2</th>\n",
       "      <th>Smiles_1</th>\n",
       "      <th>Smiles_2</th>\n",
       "      <th>F%_Rat_1</th>\n",
       "      <th>...</th>\n",
       "      <th>permeability_2</th>\n",
       "      <th>efflux_1</th>\n",
       "      <th>efflux_2</th>\n",
       "      <th>hERG_IC50_1</th>\n",
       "      <th>hERG_IC50_2</th>\n",
       "      <th>hERG_mixedIC50_1</th>\n",
       "      <th>hERG_mixedIC50_2</th>\n",
       "      <th>logD_CDD_1</th>\n",
       "      <th>logD_CDD_2</th>\n",
       "      <th>Num_Consts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1==&gt;2</td>\n",
       "      <td>(1,2)</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>{1: [1, 2, 3, 4, 5, 6], 17071: [1048406, 10484...</td>\n",
       "      <td>KT-0013567</td>\n",
       "      <td>KT-0013672</td>\n",
       "      <td>C1=C(C2=CC=CC=C2)N(C2=CC=C(NC(C)=O)C=C2)C(=O)/...</td>\n",
       "      <td>C1=C(C2=CC=CC=C2)N(C2=CC=C(NC(C)=O)C=C2)C(=O)/...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.74391</td>\n",
       "      <td>4.26768</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2==&gt;1</td>\n",
       "      <td>(1,2)</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>{1: [], 17071: []}</td>\n",
       "      <td>KT-0013672</td>\n",
       "      <td>KT-0013567</td>\n",
       "      <td>C1=C(C2=CC=CC=C2)N(C2=CC=C(NC(C)=O)C=C2)C(=O)/...</td>\n",
       "      <td>C1=C(C2=CC=CC=C2)N(C2=CC=C(NC(C)=O)C=C2)C(=O)/...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.26768</td>\n",
       "      <td>4.74391</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10==&gt;1592</td>\n",
       "      <td>(10,1592)</td>\n",
       "      <td>10</td>\n",
       "      <td>1592</td>\n",
       "      <td>{942: [62186, 62187, 62188, 62189, 62190, 62191]}</td>\n",
       "      <td>KT-0035007</td>\n",
       "      <td>KT-0035717</td>\n",
       "      <td>C1=CC(Br)=CC=C1[C@@H]1C[C@H]1C(=O)N1CC(C2=CC=C...</td>\n",
       "      <td>O=C(C1=CNN=C1I)N1CC(C2=CC=C3C(=C2)NC(C(=O)N(C)...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.60718</td>\n",
       "      <td>2.16124</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   pair_info    pair_id compound1_id compound2_id  \\\n",
       "0      1==>2      (1,2)            1            2   \n",
       "1      2==>1      (1,2)            2            1   \n",
       "2  10==>1592  (10,1592)           10         1592   \n",
       "\n",
       "                                         pair_detail     KT_id_1     KT_id_2  \\\n",
       "0  {1: [1, 2, 3, 4, 5, 6], 17071: [1048406, 10484...  KT-0013567  KT-0013672   \n",
       "1                                 {1: [], 17071: []}  KT-0013672  KT-0013567   \n",
       "2  {942: [62186, 62187, 62188, 62189, 62190, 62191]}  KT-0035007  KT-0035717   \n",
       "\n",
       "                                            Smiles_1  \\\n",
       "0  C1=C(C2=CC=CC=C2)N(C2=CC=C(NC(C)=O)C=C2)C(=O)/...   \n",
       "1  C1=C(C2=CC=CC=C2)N(C2=CC=C(NC(C)=O)C=C2)C(=O)/...   \n",
       "2  C1=CC(Br)=CC=C1[C@@H]1C[C@H]1C(=O)N1CC(C2=CC=C...   \n",
       "\n",
       "                                            Smiles_2 F%_Rat_1  ...  \\\n",
       "0  C1=C(C2=CC=CC=C2)N(C2=CC=C(NC(C)=O)C=C2)C(=O)/...      NaN  ...   \n",
       "1  C1=C(C2=CC=CC=C2)N(C2=CC=C(NC(C)=O)C=C2)C(=O)/...      NaN  ...   \n",
       "2  O=C(C1=CNN=C1I)N1CC(C2=CC=C3C(=C2)NC(C(=O)N(C)...      NaN  ...   \n",
       "\n",
       "  permeability_2 efflux_1 efflux_2 hERG_IC50_1 hERG_IC50_2 hERG_mixedIC50_1  \\\n",
       "0            NaN      NaN      NaN         NaN         NaN              NaN   \n",
       "1            NaN      NaN      NaN         NaN         NaN              NaN   \n",
       "2            NaN      NaN      NaN         NaN         NaN              NaN   \n",
       "\n",
       "  hERG_mixedIC50_2 logD_CDD_1 logD_CDD_2 Num_Consts  \n",
       "0              NaN    4.74391    4.26768          2  \n",
       "1              NaN    4.26768    4.74391          2  \n",
       "2              NaN    4.60718    2.16124          1  \n",
       "\n",
       "[3 rows x 24 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##\n",
    "dataTable = pd.DataFrame.from_dict(dataDict).T\n",
    "dataTable['Num_Consts'] = dataTable['pair_detail'].apply(lambda x: len(x))\n",
    "dataTable = dataTable.sort_values(by=[\"pair_id\", \"pair_info\"], ascending=[True, True]).reset_index(drop=True)\n",
    "print(dataTable.shape)\n",
    "dataTable.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cid = 10\n",
    "prop_id = 6\n",
    "cond_1 = (dbTable_propValue[\"compound_id\"]==cid)\n",
    "cond_2 = (dbTable_propValue[\"property_name_id\"]==prop_id)\n",
    "dbTable_propValue[cond_1 & cond_2].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataDict_tables[\"rule_environment_statistics\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataTable_rule_env_stats = copy.deepcopy(dataDict_tables[\"rule_environment_statistics\"])\n",
    "\n",
    "dataTable_rule_env_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataTable_rule_env_stats = copy.deepcopy(dataDict_tables[\"rule_environment_statistics\"])\n",
    "dataTable_rule_env_stats.drop(columns=['id', 'kurtosis','skewness', 'paired_t', 'p_value', 'q1', 'median', 'q3'], inplace=True)\n",
    "dataTable_rule_env_stats = dataTable_rule_env_stats.merge(dataDict_tables[\"property_name\"], left_on='property_name_id', right_on='id')\n",
    "dataTable_rule_env_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataTable_rule_env_fp = copy.deepcopy(dataDict_tables[\"environment_fingerprint\"])\n",
    "dataTable_rule_env_fp.rename(columns={'id':'environment_fingerprint_id', \n",
    "                                      'pseudosmiles':'rule_env_fp_pseudosmiles',\n",
    "                                      'smarts':'rule_env_fp_smarts', \n",
    "                                      'parent_smarts':'rule_env_fp_parent_smarts'})\n",
    "dataTable_rule_env_fp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. clean up data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## -------------------- clean up rule table & merge rule smiles --------------------\n",
    "dataTable_rules = copy.deepcopy(dataDict_tables[\"rule\"])\n",
    "dataTable_rules.rename(columns={'id':'rule_id'},  inplace=True)\n",
    "\n",
    "## from\n",
    "dataTable_rules = dataTable_rules.merge(dataDict_tables[\"rule_smiles\"], left_on=['from_smiles_id'], right_on=['id'])\n",
    "dataTable_rules.drop(columns=['id', 'num_heavies'], inplace=True)\n",
    "dataTable_rules.rename(columns={'smiles':'from_smiles'}, inplace=True)\n",
    "dataTable_rules.head(3)\n",
    "\n",
    "## to \n",
    "dataTable_rules = dataTable_rules.merge(dataDict_tables[\"rule_smiles\"], left_on=['to_smiles_id'], right_on=['id'])\n",
    "dataTable_rules.drop(columns=['id', 'num_heavies'], inplace=True)\n",
    "dataTable_rules.rename(columns={'smiles':'to_smiles'}, inplace=True)\n",
    "\n",
    "## -------------------- merge rule table and rule env table --------------------\n",
    "dataTable_rule_env = copy.deepcopy(dataDict_tables[\"rule_environment\"])\n",
    "dataTable_rule_env.rename(columns={'id':'rule_environment_id', 'radius':'rule_env_radius', 'num_pairs':'rule_env_num_pairs'},  inplace=True)\n",
    "dataTable_rule_env = dataTable_rule_env.merge(dataTable_rules, on='rule_id')\n",
    "\n",
    "## -------------------- merge rule env table and rule_env_stats info --------------------\n",
    "## clean up rule-env-stats table\n",
    "dataTable_rule_env_stats = copy.deepcopy(dataDict_tables[\"rule_environment_statistics\"])\n",
    "dataTable_rule_env_stats.drop(columns=['id', 'kurtosis','skewness', 'paired_t', 'p_value', 'q1', 'median', 'q3'], inplace=True)\n",
    "dataTable_rule_env_stats = dataTable_rule_env_stats.merge(dataDict_tables[\"property_name\"], left_on='property_name_id', right_on='id')\n",
    "\n",
    "## merge\n",
    "dataTable_rule_env = dataTable_rule_env.merge(dataTable_rule_env_stats, left_on=['rule_environment_id'], right_on=['rule_environment_id'])\n",
    "\n",
    "\n",
    "## -------------------- merge rule env table and rule_env_fp info --------------------\n",
    "dataTable_rule_env_fp = copy.deepcopy(dataDict_tables[\"environment_fingerprint\"])\n",
    "dataTable_rule_env_fp.rename(columns={'id':'environment_fingerprint_id', \n",
    "                                      'pseudosmiles':'rule_env_fp_pseudosmiles',\n",
    "                                      'smarts':'rule_env_fp_smarts', \n",
    "                                      'parent_smarts':'rule_env_fp_parent_smarts'}, inplace=True)\n",
    "\n",
    "dataTable_rule_env = dataTable_rule_env.merge(dataTable_rule_env_fp, on=['environment_fingerprint_id'])\n",
    "# dataTable_rule_env.drop(columns=['id'], inplace=True)    #, 'smarts', 'parent_smarts'\n",
    "dataTable_rule_env.rename(columns={'environment_fingerprint_id':'rule_env_fingerprint_id',\n",
    "                                   'pseudosmiles':'rule_env_fp_pseudosmiles', \n",
    "                                   'smarts':'rule_env_fp_smarts', \n",
    "                                   'parent_smarts':'rule_env_fp_parent_smarts', }, inplace=True)\n",
    "\n",
    "\n",
    "# cols_in_order = ['rule_id', 'from_smiles_id', 'from_smiles', 'to_smiles_id', 'to_smiles', \n",
    "#                  'rule_environment_id', 'rule_env_num_pairs', 'rule_env_radius', 'rule_env_fingerprint_id', \n",
    "#                  'rule_env_fp_pseudosmiles', 'rule_env_fp_smarts', 'rule_env_fp_parent_smarts']\n",
    "# dataTable_rule_env = dataTable_rule_env[cols_in_order]\n",
    "\n",
    "dataTable_rule_env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataDict_tables[\"rule_smiles\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataTable = copy.deepcopy(dataDict_tables[\"pair\"])\n",
    "dataTable.head(3)\n",
    "\n",
    "## ------------------- add compound structure & property data -------------------\n",
    "table_merge = dataDict_tables[\"compound\"]\n",
    "\n",
    "## compound-1 (from)\n",
    "dataTable = dataTable.merge(table_merge, left_on=['compound1_id'], right_on=['id'])\n",
    "dataTable.drop(columns=['id_y', 'clean_smiles', 'clean_num_heavies'], inplace=True)\n",
    "dataTable.rename(columns={'id_x':'id', 'public_id':'KT_number_1', 'input_smiles':'smiles_1'}, inplace=True)\n",
    "\n",
    "## compound-2 (to)\n",
    "dataTable = dataTable.merge(table_merge, left_on=['compound2_id'], right_on=['id'])\n",
    "dataTable.drop(columns=['id_y', 'clean_smiles', 'clean_num_heavies'], inplace=True)\n",
    "dataTable.rename(columns={'id_x':'id', 'public_id':'KT_number_2', 'input_smiles':'smiles_2'}, inplace=True)\n",
    "\n",
    "## ------------------- add compound prop data -------------------\n",
    "table_merge = dataDict_tables[\"compound_property\"]\n",
    "\n",
    "## compound-1 (from)\n",
    "dataTable = dataTable.merge(table_merge, left_on=['compound1_id'], right_on=['compound_id'])\n",
    "dataTable.drop(columns=['id_y', 'compound_id'], inplace=True)\n",
    "dataTable.rename(columns={'id_x':'id', 'value':'property_values_1'}, inplace=True)\n",
    "\n",
    "## compound-2 (to)\n",
    "dataTable = dataTable.merge(table_merge, left_on=['compound2_id', 'property_name_id'], right_on=['compound_id', 'property_name_id'])\n",
    "dataTable.drop(columns=['id_y', 'compound_id'], inplace=True)\n",
    "dataTable.rename(columns={'id_x':'id', 'value':'property_values_2'}, inplace=True)\n",
    "\n",
    "## add property name\n",
    "table_merge = dataDict_tables[\"property_name\"]\n",
    "dataTable = dataTable.merge(table_merge, left_on=['property_name_id'], right_on=['id'])\n",
    "dataTable.drop(columns=['id_y'], inplace=True)\n",
    "dataTable.rename(columns={'id_x':'id', 'name':'property_name'}, inplace=True)\n",
    "\n",
    "## ------------------- add constant pieces data of the match pair -------------------\n",
    "table_merge = dataDict_tables[\"constant_smiles\"]\n",
    "dataTable = dataTable.merge(table_merge, left_on=['constant_id'], right_on=['id'])\n",
    "dataTable.drop(columns=['id_y'], inplace=True)\n",
    "dataTable.rename(columns={'id_x':'id', 'smiles':'constant_smiles'}, inplace=True)\n",
    "\n",
    "## ------------------- add rule env data -------------------\n",
    "table_merge = dataDict_tables[\"rule_environment\"]\n",
    "dataTable = dataTable.merge(table_merge, left_on=['rule_environment_id'], right_on=['id'])\n",
    "dataTable.drop(columns=['id_y'], inplace=True)\n",
    "dataTable.rename(columns={'id_x':'id', 'radius':'rule_env_radius', 'num_pairs':'rule_env_num_pairs'}, inplace=True)\n",
    "\n",
    "## ------------------- add rule info -------------------\n",
    "table_merge = dataDict_tables[\"rule\"]\n",
    "dataTable = dataTable.merge(table_merge, left_on=['rule_id'], right_on=['id'])\n",
    "dataTable.drop(columns=['id_y'], inplace=True)    #'rule_id'\n",
    "dataTable.rename(columns={'id_x':'id'}, inplace=True)\n",
    "\n",
    "table_merge = dataDict_tables[\"rule_smiles\"]\n",
    "dataTable = dataTable.merge(table_merge, left_on=['from_smiles_id'], right_on=['id'])\n",
    "dataTable.drop(columns=['id_y', 'from_smiles_id', 'num_heavies'], inplace=True)    #'num_heavies'\n",
    "dataTable.rename(columns={'id_x':'id', 'smiles':'rule_from_smiles'}, inplace=True)\n",
    "\n",
    "table_merge = dataDict_tables[\"rule_smiles\"]\n",
    "dataTable = dataTable.merge(table_merge, left_on=['to_smiles_id'], right_on=['id'])\n",
    "dataTable.drop(columns=['id_y', 'to_smiles_id', 'num_heavies'], inplace=True)\n",
    "dataTable.rename(columns={'id_x':'id', 'smiles':'rule_to_smiles'}, inplace=True)\n",
    "\n",
    "## ------------------- add rule env stats -------------------\n",
    "table_merge = dataDict_tables[\"rule_environment_statistics\"]\n",
    "dataTable = dataTable.merge(table_merge, \n",
    "                            left_on=['rule_environment_id', 'property_name_id'], \n",
    "                            right_on=['rule_environment_id', 'property_name_id'])\n",
    "\n",
    "drop_cols = ['kurtosis', 'skewness', 'paired_t', 'p_value', 'q1', 'q3', 'median', 'std']\n",
    "dataTable.drop(columns=['id_y']+drop_cols, inplace=True)\n",
    "dataTable.rename(columns={'id_x':'id', 'count':'rule_env_count', 'avg':'rule_env_avg', \n",
    "                          'min':'rule_env_min', 'max':'rule_env_max'}, inplace=True)\n",
    "\n",
    "## ------------------- add rule env environment_fingerprint data -------------------\n",
    "table_merge = dataDict_tables[\"environment_fingerprint\"]\n",
    "## to be added\n",
    "\n",
    "## ------------------- remove useless cols -------------------\n",
    "dataTable.drop(columns=['id', 'compound1_id', 'compound2_id', 'constant_id', 'rule_environment_id', 'property_name_id'], inplace=True)\n",
    "print(dataTable.shape)\n",
    "dataTable.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GeneratePairID(row, col_mol_id_1='KT_number_1', col_mol_id_2='KT_number_2'):\n",
    "    mol_id_1 = row[col_mol_id_1]\n",
    "    mol_id_2 = row[col_mol_id_2]\n",
    "    pair_id = str(mol_id_1) + '=>' + str(mol_id_2)\n",
    "    \n",
    "    mol_id_1_num = int(str(mol_id_1).split('-')[1])\n",
    "    mol_id_2_num = int(str(mol_id_2).split('-')[1])\n",
    "    pair_couple = (np.min([mol_id_1_num, mol_id_2_num]), np.max([mol_id_1_num, mol_id_2_num]))\n",
    "    return pd.Series([pair_id, pair_couple])\n",
    "\n",
    "dataTable[['Pair_id', 'PairInfo']] = dataTable.apply(lambda row: GeneratePairID(row, col_mol_id_1='KT_number_1', col_mol_id_2='KT_number_2'), axis=1)\n",
    "print(dataTable.shape)\n",
    "\n",
    "################################################################################################\n",
    "def calculate_heavy_atoms(molecule_smiles):\n",
    "    try:\n",
    "        mol = Chem.MolFromSmiles(molecule_smiles)\n",
    "        num_heavy_atoms = mol.GetNumHeavyAtoms()\n",
    "    except Exception as e:\n",
    "        print('Error', e)\n",
    "        num_heavy_atoms = np.nan\n",
    "    return num_heavy_atoms\n",
    "\n",
    "dataTable['constant_size'] = dataTable['constant_smiles'].apply(calculate_heavy_atoms)\n",
    "dataTable.sort_values(by=['PairInfo', 'Pair_id', 'rule_env_radius', 'constant_size'], ascending=[True, True, True, False], inplace=True)\n",
    "print(dataTable.shape)\n",
    "\n",
    "################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_heavy_atoms(molecule_smiles):\n",
    "    try:\n",
    "        mol = Chem.MolFromSmiles(molecule_smiles)\n",
    "        num_heavy_atoms = mol.GetNumHeavyAtoms()\n",
    "    except Exception as e:\n",
    "        print('Error', e)\n",
    "        num_heavy_atoms = np.nan\n",
    "    return num_heavy_atoms\n",
    "\n",
    "dataTable['constant_size'] = dataTable['constant_smiles'].apply(calculate_heavy_atoms)\n",
    "dataTable.sort_values(by=['PairInfo', 'Pair_id', 'rule_env_radius', 'constant_size'], ascending=[True, True, True, False], inplace=True)\n",
    "# dataTable.to_csv(f'./results/Compounds_All_4_informatics.csv', index=False)\n",
    "dataTable.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. removed the \"duplicated\" rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataTable.sort_values(by=['PairInfo', 'rule_env_radius', 'constant_size'], ascending=[True, True, False], inplace=True)\n",
    "dataTable_rmDup = dataTable.drop_duplicates(subset=['PairInfo', 'property_name'], keep='first', inplace=False)\n",
    "print(dataTable_rmDup.shape)\n",
    "dataTable_rmDup.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### append symetric rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rename_symetric_dict = {\n",
    "    'KT_number_1': 'KT_number_2',\n",
    "    'smiles_1': 'smiles_2',\n",
    "    'KT_number_2': 'KT_number_1',\n",
    "    'smiles_2': 'smiles_1',\n",
    "    'property_values_1': 'property_values_2',\n",
    "    'property_values_2': 'property_values_1', \n",
    "    'rule_from_smiles': 'rule_to_smiles',\n",
    "    'rule_to_smiles': 'rule_from_smiles'}\n",
    "dataTable_rmDup_symetric = dataTable_rmDup.rename(columns=rename_symetric_dict, inplace=False)\n",
    "dataTable_rmDup_symetric['Pair_id'] = dataTable_rmDup_symetric['KT_number_1'] + '=>' + dataTable_rmDup_symetric['KT_number_2']\n",
    "for col in ['rule_env_avg', 'rule_env_min', 'rule_env_max']:\n",
    "    dataTable_rmDup_symetric[col] = dataTable_rmDup_symetric[col] * -1\n",
    "dataTable_rmDup_symetric.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataTable_rmDup_all = dataTable_rmDup._append(dataTable_rmDup_symetric, ignore_index=True)\n",
    "dataTable_rmDup_all['rule_env_min'] = dataTable_rmDup_all['rule_env_min'].apply(lambda x:round(x, 2)).astype('str')\n",
    "dataTable_rmDup_all['rule_env_max'] = dataTable_rmDup_all['rule_env_max'].apply(lambda x:round(x, 2)).astype('str')\n",
    "dataTable_rmDup_all['rule_env_range'] = '('+ dataTable_rmDup_all['rule_env_min'] + ',' + dataTable_rmDup_all['rule_env_max'] +')'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataTable_rmDup_all.sort_values(by=['PairInfo', 'property_name', 'Pair_id'], ascending=[True, True, True], inplace=True)\n",
    "dataTable_rmDup_all = dataTable_rmDup_all.reset_index(drop=True)\n",
    "# dataTable_rmDup_all.to_csv(f'./results/Compounds_All_4_informatics_rmDups.csv', index=False)\n",
    "dataTable_rmDup_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
